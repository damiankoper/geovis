\chapter{Silnik}

Rozdział ten opisuje główny komponent tworzonego systemu nazwanego Silnikiem. Odpowiedzialny jest on za dostarczenie interfejsu definiowania trójwymiarowej wizualizacji i~jej późniejsze wyświetlanie. Narzuca również sposób pracy kamery i~umożliwia konfigurację jej parametrów.

Wszystkie obiekty wyświetlane na scenie, razem z~definicją ich wyglądu, tekstur i~dynamiki ruchów dostarcza wizualizacja. Jej obiekty mogą reagować na zdarzenia, które generuje użytkownik. Zainicjowanie procedury obsługi tych zdarzeń również komponent Silnika.

Najpierw w~sposób uproszczony opisany został sposób renderowania grafiki z~wykorzystaniem API WebGL oraz biblioteki Three.js. Następnie przedstawiono mechanizmy sterujące pracą kamery, a~następnie implementacja komponentu Silnika i~opisanych mechanizmów.

\section{WebGL i~ESSL}

WebGL jest dostępnym z~poziomu języka JavaScript API pozwalającym na renderowanie grafiki 3D w~przeglądarce. Złożone obiekty rysowane są tylko za pomocą punktów, linii i~trójkątów.  WebGL działa w~trybie \textit{immidiate}, który to wymusza na aplikacji wykonywanie bezpośrednio niskopoziomowych komend rysujących podstawowe obiekty 3D. Aplikacja korzystająca z~WebGL musi sama definiować abstrakcje podstawowych obiektów takich jak scena, kamera, czy światło. Podejście to jest bardzo elastyczne i~pozwala na optymalizację implementowanych rozwiązań w~zależności od potrzeb\cite[Rozdział 1]{RealTime3DGraphics}. WebGL korzysta z~akceleracji sprzętowej podczas renderowania grafiki - działa na GPU. W przypadku kart graficznych bez wsparcia dla ten technologii przeglądarki Google Chrome i~Internet Explorer 11 umożliwiają rysowanie z~użyciem CPU.

Drugim podejściem do renderowania grafiki jest podejście \textit{retained}, gdzie biblioteki z~niego korzystające implementują swoją abstrakcję sceny i~same zajmują się jej rysowaniem. Przykładem takiej biblioteki jest Windows Presentation Foundation\cite{WPF}.

Dostęp do API WebGL uzyskać można poprzez kontekst elementu \texttt{Canvas}. Na listingu \ref{lst:webglContext} pokazano pobranie kontekstu API WebGL do zmiennej \texttt{gl}. Wszystkie interakcje związane z~użyciem API będą odbywały się z~użyciem pobranego obiektu kontekstu. Numer w~identyfikatorze \texttt{’webgl2’} mówi, że używamy WebGL w~wersji drugiej.

\begin{lstlisting}[language=javascript, label={lst:webglContext}, caption={Pobranie kontekstu API WebGL do zmiennej}]
const canvas = document.getElementById('vis-container');
const gl = canvas.getContext('webgl2');
\end{lstlisting}

Obiekt kontekstu działa jak maszyna stanów. Przechowuje ustawiony stan do czasu jego zmiany przez aplikację. Wszystkie operacje renderowania grafiki korzystają z~globalnie ustawionych parametrów, które definiują stan kontekstu i~mają bezpośredni wpływ na efekt końcowy\cite[Rozdział 1]{RealTime3DGraphics}.

\subsubsection{Rysowanie sceny}

Rysowanie obiektu rozpoczyna się od utworzenia buforów danych i~umieszczenia w~nich współrzędnych wierzchołków oraz kolejności, według której wierzchołki mają brać udział w~procesie rysowania. Kolejność ma istotne znaczenie w~przypadku różnych trybów rysowania oraz, Cullingu czyli określania widocznej strony rysowanego trójkąta. Bufory są reprezentowane zewnętrznie jako tablice \texttt{TypedArray}. Przechowują one jedynie surowe dane w~postaci binarnej \cite{TypedArrays}. W języku JavaScript występuje jeden typ \texttt{number} przechowujący liczby, które wewnętrznie reprezentowane są jako 64b liczba zmiennoprzecinkowa. Dodatkowo każda zmienna numeryczna jest obiektem typu \texttt{Number} z~własnymi metodami. Użycie buforów z~interfejsem tablicy przyspiesza operacje na danych.

\subsubsection{Shadery}

W WebGL'u \textit{programem} nazywane są skompilowane przez kontekst shadery. Są to krótkie programy napisane w~specjalistycznym języku, którym w~przypadku WebGL'a jest ESSL(ang. OpenGL ES Shading Language). Przypomina on składnią język C/C++\cite{ESSL} i~zawiera wbudowane funkcje wymagane do operacji matematycznych takich jak iloczyn skalarny wektorów, czy mnożenie macierzy. Na wspomniany \textit{program} składają się dwa shadery - \texttt{vertex shader} i~\texttt{fragment shader}. \texttt{Vertex shader}, uruchamiany jako pierwszy, pobiera dane o~wierzchołkach z~buforów, oraz korzystając ze stałych (\texttt{uniforms}) oblicza finalną pozycję wierzchołka. W większości przypadków shader ten odpowiada również za obliczenie innych parametrów wierzchołka takich jak kolor, jego wektor normalny, czy też współrzędne tekstur. Dla każdego wierzchołka wyliczone wartości wysyłane są dalej do shadera \texttt{fragment shader}.

\texttt{Fragment shader} odpowiada za wyliczenie koloru pojedynczego pixela. Dale wysłane z~\texttt{vertex shader}'a w~zmiennych typu \texttt{varying} są automatycznie interpolowane dla każdego punktu w~renderowanym trójkącie na podstawie trzech wierzchołków.

W shaderach, po dostarczeniu odpowiednich danych, realizowane są abstrakcje takie jak kamera, oświetlenie, czy materiały.

\subsubsection{Obliczanie finalnej pozycji wierzchołków}

W grafice 3D każdy model reprezentowany jest przez zbiór punktów i~informacji o~kolejności ich rysowania. Model może mieć swoją pozycję w~świecie 3D, a~obserwator może znajdować się w~różnych miejscach sceny. WebGL sam w~sobie nie posiada abstrakcji kamery i~do wyświetlenia sceny z~konkretnej perspektywy konieczne jest przemieszczenie wszystkich wierzchołków geometrii. Transformacja pozycji wierzchołków odbywa się za pomocą przekształceń afinicznych, które transformują pozycję zbioru wierzchołków i~nie zaburzają relacji pomiędzy nimi. Efektywnie transformacja taka jest mnożeniem macierzy transformacji o~wymiarach 4x4 i~wektora z~dodaną czwartą współrzędną równą 1, co daje nowy wektor współrzędnych wierzchołka.

Przekształcenia związane z~pozycją modelu i~kamery w~świecie wyrażane są za pomocą macierzy. Macierzowy opis przekształceń możliwy jest dzięki zastosowaniu współrzędnych jednorodnych\cite{Homogeneous}. Transformacja pozycji modelu odbywa się z~pomocą macierzy $M$, a~transformacja pozycji związana z~położeniem kamery z~pomocą macierzy widoku $V$. Wyliczanie współrzędnych wierzchołka w~układzie współrzędnych świata pokazano w~równaniu \ref{eq:MV}.

Aby uzyskać wyjściową pozycję piksela na ekranie konieczne jest pomnożenie macierzy projekcji i~wektora pozycji wierzchołka w~układzie współrzędnych świata (równanie \ref{eq:MVP}). Macierz projekcji odpowiada za transformację współrzędnych wierzchołka do sześcianu o~wymiarach 2x2x2 i~środku w~punkcie $(0, 0, 0)$. Transformacja ta może być perspektywiczna, gdzie przekształceniu ulega przestrzeń w~kształcie ostrosłupa ściętego. Może być też ortograficzna, gdzie przekształceniu ulega przestrzeń w~kształcie prostopadłościanu. Punkty leżące poza tą przestrzenią nie są rysowane. Współrzędne $(x, y)$ transformowanych wierzchołków są współrzędnymi \textit{NDC} (ang. Normalized Device Coordinates), niezależnymi od urządzenia. Dzięki temu mogą być one łatwo przekształcone na piksele elementu \texttt{Canvas}, gdzie punkt $(0, 0)$ znajduje się w~lewem górnym rogu. Podejście to uniezależnia generowanie pikseli od elementu wyświetlającego, do którego trzeba dostosować tylko sposób przekształcenia współrzędnych \textit{NDC}.

\begin{equation}
    \label{eq:MV}
    p' = VM \cdot \begin{bmatrix}
        p_{1} \\
        p_{2} \\
        p_{3} \\ 
        1
      \end{bmatrix}
\end{equation}
\begin{eqexpl}[25mm]
    \item{$M$} macierz transformacji pozycji modelu
    \item{$V$} macierz transformacji widoku
    \item{$p'$} wektor pozycji wierzchołka w~układzie współrzędnych widoku
    \item{$p$} wektor pozycji modelu w~układzie współrzędnych świata
\end{eqexpl}

\begin{equation}
\label{eq:MVP}
    v = P \cdot \begin{bmatrix}
        p'_{1} \\
        p'_{2} \\
        p'_{3} \\ 
        1
      \end{bmatrix}
\end{equation}
\begin{eqexpl}[25mm]
    \item{$P$} macierz projekcji
    \item{$p'$} wektor pozycji wierzchołka w~układzie współrzędnych widoku
\end{eqexpl}
\vspace{\baselineskip}
Kalkulacja pozycji modeli oraz kamery ma szczególne znaczenie przy złożonym zachowaniu kamery oraz sceny w~komponencie Silnika.

\subsection{Three.js}

Three.js\cite{threejs} jest biblioteką 3D, która domyślnie do renderowania grafiki używa WebGL. Ułatwia ona rozpoczęcie pracy z~grafiką 3D i~jednocześnie nie nakłada ograniczeń związanych z~niskopoziomową konfiguracją wyświetlanej sceny. Pozwala ona na opisanie sceny, obiektów, świateł i~materiałów w~postaci obiektowej. Posiada rozbudowany system animacji oraz wsparcie dla systemów wirtualnej rzeczywistości. Na listingu \ref{lst:threejs:base} pokazano kod aplikacji, która wyświetla zielony sześcian.

\begin{lstlisting}[language=javascript, label={lst:threejs:base}, caption={Hello World w~świecie grafiki 3D}]
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );
    
    const renderer = new THREE.WebGLRenderer();
    renderer.setSize( window.innerWidth, window.innerHeight );
    document.body.appendChild( renderer.domElement );

    const geometry = new THREE.BoxGeometry();
    const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
    const cube = new THREE.Mesh( geometry, material );
    scene.add( cube );

    camera.position.z = 5;

    function animate() {
        requestAnimationFrame( animate );
        renderer.render( scene, camera );
    }
    animate();
\end{lstlisting}

Na początku tworzony jest obiekt sceny, która jest kontenerem na pozostałe wyświetlane obiekty oraz światła. Następnie tworzony jest obiekt kamery, który definiuje właściwości, w~tym wypadku, projekcji perspektywicznej. Utworzony dalej obiekt \texttt{THREE.WegGLRenderer} odpowiedzialny jest za utworzenie i~przechowywanie referencji do obiektu \texttt{Canvas}, na którym, w~głównej pętli programu, rysuje dostarczoną scenę z~perspektywy wybranej kamery. Odpowiada za to wywołanie \texttt{renderer.render(scene, camera)}.

Geometrię kostki definiuje obiekt \texttt{THREE.BoxGeometry}, która z~domyślnymi argumentami konstruktora jest sześcianem o~wymiarach 1x1x1. Obiekt ten posiada atrybuty ułatwiające zarządzanie wygenerowaną geometrią. Zwykłe obiekty geometrii są konwertowane do typu \texttt{BufferGeometry} w~procesie renderowania, Wtedy dane wierzchołków są umieszczane w~buforach, które mogą być bezpośrednio wykorzystane w~interakcji z~WebGL'em. Three.js pozwala tworzyć geometrię w~sposób bardziej efektywny, jednak gorzej zarządzalny, wykorzystując klasy pochodne klasy \texttt{BufferGeometry}, takie jak \texttt{BoxBufferGeometry}.

Elementy wyglądu rysowanych geometrii określa materiał. W Three.js obiektami je reprezentujące są pochodne klasy \texttt{Material}. Umożliwiają ustawienie koloru, tekstur, różnego rodzaju map, a~w przypadku światła parametry jego interakcji z~powierzchnią obiektu. W procesie rysowania obiektu, atrybuty jego materiału, oraz atrybuty obiektów ważnych dla wyglądu rysowanego obiektu, na przykład świateł, są wysyłane do shaderów w~postaci stałych (\texttt{uniforms}). Sam materiał definiuje jednoznacznie działanie shaderów, wykorzystanych w~procesie jego rysowania. Przykład shadera dla materiału \texttt{MeshBasicMaterial} pokazano na listingu \ref{lst:matVert}.

\begin{lstlisting}[language=C++, label={lst:matVert}, caption={
    Fragmenty vertex shadera materiału \texttt{MeshBasicMaterial}}
]
#include <common>
/* ... */

void main() {
    /* ... */
	#include <color_vertex>
    /* ... */

	#include <begin_vertex>
	/* ... */
	#include <project_vertex>
	/* ... */
}
\end{lstlisting}

Shadery różnych materiałów współdzielą pomiędzy sobą wiele swoich części. Dlatego zastosowano dyrektywę \texttt{\#include} w~celu umieszczenia w~kodzie wspólnych części. Na listingu \ref{lst:vertProject}, w~części \texttt{project\_vertex}, widać właściwy proces obliczania pozycji wierzchołka przedstawiony na równaniach \ref{eq:MV} i~\ref{eq:MVP}. Macierz projekcji mnożona jest przez połączoną macierz modelu i~widoku oraz zmienną wektorową \texttt{mvPosition}. Wynikowy wektor wpisywany jest do specjalnej zmiennej globalnej \texttt{gl\_Position}, której zawartość informuje resztę składowych procesu generowania grafiki o~wyniku kalkulacji. 

\begin{lstlisting}[language=C++, label={lst:vertProject}, caption={
    Fragmenty części \texttt{project\_vertex} vertex shadera}
]
vec4 mvPosition = vec4( transformed, 1.0 );
/* ... */
mvPosition = modelViewMatrix * mvPosition;
gl_Position = projectionMatrix * mvPosition;
\end{lstlisting}

Three.js dostarcza również wiele narzędzi ułatwiających operacje matematyczne na wektorach oraz macierzach. Pozwala między innymi na interpolację liniową i~sferyczną wektorów, generowanie macierzy transformacji, czy reprezentowanie obrotów za pomocą kątów Eulera lub kwaternionów.

\section{Praca kamery}
\label{sec:camera}

Komponent Silnika wyświetla scenę, w~której kamera orbituje wokół jednego punktu. Dodatkowo użytkownik może zmienić orientację kamery względem punktu na powierzchni sfery. Opis pracy kamery odnosić się będzie do obiektu sfery i~jej powierzchni, jednak nic nie stoi na przeszkodzie, aby kamera orbitowała wokół innego obiektu. W tym podrozdziale opis mechanizmów jest przedstawiony w~oderwaniu od ich implementacji w~projekcie. Finalnie, pozycję kamery relatywnie do środka sfery opisują dwie orbity. Orbitą, w~kontekście pracy kamery, nazwana została para wektorów określająca obrót od wektora odniesienia i~odległość od punktu jego zaczepienia.

Wspomniane orbity nazwano orbitą lokalną i~orbitą globalną. Orbita globalna odpowiedzialna jest za pozycję kamery nad punktem obiektu sfery. Orbita lokalna określa orientacją kamery względem punktu, nad którym się znajduje. Taki podział sceny wprowadza również dwa układy odniesienia.

\begin{enumerate}
    \item Układ obserwatora - układ, w~którym znajduje się obserwator i~wszystkie obiekty są pozycjonowane relatywnie do obiektu kamery. Jest to domyślny układ renderowanej sceny.
    \item Układ wizualizacji - układ, w~którym obiekty pozycjonowane są relatywnie do mogącej obracać się sfery. Obiekty umieszczane są w~obracającej się grupie.
\end{enumerate}

Żeby przybliżyć zależności pomiędzy tymi układami, można posłużyć się przykładem. Aby symulować cykl dnia i~nocy, światło musi być pozycjonowane w~układzie wizualizacji, ponieważ jest niezależne od ruchu kamery. Aby światło oświetlało zawsze widoczną stronę planety, musi być ono pozycjonowane w~układzie obserwatora. Ogólny graf sceny przedstawiono na diagramie \ref{fig:c3_scene_graph}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_scene_graph.png}
    \caption{Ogólny graf sceny wizualizacji}
    \label{fig:c3_scene_graph}
\end{figure}

\subsection{Orbita globalna}

Orbitę globalną definiują dwa wektory - $\vv{g_v}$ i~$\vv{g_{up}}$ na rysunku \ref{fig:orbits}. Pierwszy rozciągnięty jest od środka $s$ sfery do punktu $c_g$, wokół którego orbituje kamera. Drugi jest wektorem jednostkowym do niego prostopadłym określającym orientację sfery w~osi pierwszego wektora. W późniejszym opisie działanie \textit{na orbicie}, na przykład obrót orbity, oznacza wykonanie tej samej transformacji na obu wektorach. W ten sposób oba wektory nigdy nie zmienią swojej wzajemnej orientacji.

Użytkownik za pomocą myszy lub klawiatury może obrócić sferę, a~konkretnie grupę obrotu (\texttt{OrbitGroup} na diagramie \ref{fig:c3_scene_graph}) i~zawierane przez nie obiekty. Jest to efektywnie zmianą punktu, nad którym znajduje się kamera, pomimo tego, że jej pozycja się nie zmienia. Jako, że obrót sfery definiowany jest abstrakcję orbity, cała operacja sprowadza się do jej odpowiedniego obrócenia. 

Parametrami specyficznymi dla orbity globalnej są:
\begin{enumerate}
    \item tryb pracy orbity - określa czy podczas przesuwania orbity ma ona zachowywać swoją orientację w~kierunku północnym. Wydzielono tryb \textit{swobodny} i~\textit{kompas}.
\end{enumerate}

\subsection{Orbita lokalna}

Orbitę lokalną, podobnie jak globalną, definiują dwa wektory - $\vv{l_v}$ i~$\vv{l_{up}}$ na rysunku \ref{fig:orbits}. Pierwszy rozciągnięty jest od punktu $c_g$, wokół którego orbituje kamera, do kamery (punkt $c_l$). Drugi jest wektorem jednostkowym do niego prostopadłym określającym orientację kamery w~osi pierwszego wektora.

Użytkownik za pomocą myszy lub klawiatury może zmienić punkt orbitowania kamery. Jest to efektywnie zmianą położenia kamery w~układzie obserwatora. Jako, że pozycja kamery definiowany jest przez abstrakcję orbity, cała operacja sprowadza się do jej odpowiedniego obrócenia.

Pierwszy wektor orbity lokalnej może mieć zmienną długość. Reprezentuje ona odległość obserwatora do punktu na powierzchni sfery. 

Parametrami specyficznymi dla orbity lokalnej są:
\begin{enumerate}
    \item współczynnik przybliżenia - jak powinna zmienić się odległość kamery od punktu na powierzchni sfery podczas jednej akcji przybliżenia.
    \item granice przybliżenia - minimalna i~maksymalna odległość kamery od punktu na powierzchni sfery.
\end{enumerate}

\subsection{Parametry wspólne dla obu orbit}

Dla obu orbit wyróżniono wspólne parametry. Są nimi:
\begin{enumerate}
    \item granice - wyrażony w~radianach zakres współrzędnych geograficznych definiujący fragment sfery, nad którym kamera może się znaleźć. Może służyć na przykład do ograniczenia obszaru poruszania się użytkownika tylko do jednej półkuli lub jednego miasta.
    \item prędkość obrotu - współczynnik sterujący prędkością obrotu danej orbity.
\end{enumerate}

Wszystkie parametry, ogólne i~te specyficzne dla każdej z~orbit mogą być konfigurowane przez wizualizację.

\begin{figure}[]
    \centering
    \input{drawings/orbits.tex}
    \caption{Schemat orbit w~specyficznym przypadku dwóch wymiarów}
    \label{fig:orbits}
\end{figure}



\subsection{Obrót orbity globalnej}

Algorytm obrotu orbity globalnej wykonywany jest dla każdego zdarzenia przesunięcia myszy użytkownika podczas gestu chwycenia, przeciągnięcia i~upuszczenia wygenerowanym przez element \texttt{Canvas}. Obrót wymaga obliczenia jego chwilowej osi i~kąta.

\subsubsection{Kwaterniony}
Kwaterniony są rozszerzeniem liczb zespolonych \cite{Quaternions}. Mają one postać:
\begin{equation}
    \label{eq:q_1}
    q = a~+ bi + cj + dk : a,\,b,\,c,\,d\in\mathbb{R}
\end{equation}
gdzie, podobnie jak w~przypadku liczb zespolonych, zachodzi zależność:
\begin{equation}
    \label{eq:q_2}
    i^2 = j^2 = k^2 = ijk =  -1
\end{equation}

Ich mnożenie następuje, z~uwzględnieniem zależności z~równania \ref{eq:q_2}, tak jak mnożenie wielomianów.

Kwaternion może być interpretowany jak suma skalaru z~wektorem, gdzie współczynnik $a$ jest skalarem, a~$b$, $c$ i~$d$ są współrzędnymi wektora. Kwaterniony jednostkowe służą między innymi do reprezentacji obrotów w~przestrzeni 3D. Rozwiązują one problemy związane z~reprezentacją obrotów poprzez kąty Eulera. Obrót taki jest zdefiniowany poprzez obroty wokół każdej z~osi układu współrzędnych. Obracanie z~ich użyciem, w~pewnym kombinacjach obrotu może skutkować efektem gimbal-lock, który powoduje zanikiem stopnia swobody obrotu. Dlatego w~tym przypadku ważna jest kolejność obrotów. Stosując kąty Eulera niemożliwa jest bezpośrednia interpolacja sferyczna pomiędzy dwoma zdefiniowanymi obrotami.

Konstrukcja kwaternionu definiującego dany obrót jest następująca:
\begin{samepage}
    \begin{equation}
        \label{eq:q_3}
        q = \cos{\frac{\theta}{2}} + (u_xi+u_yj+u_zk)\sin{\frac{\theta}{2}}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$\theta$} kąt obrotu
        \item {$u$} wektor jednostkowy definiujący oś obrotu
        \item {$i, j, k$} jednostki urojone kwaternionu
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Obrót wektora jest sprowadzeniem wektora do kwaternionu ze współczynnikiem $a = 0$ i~pomnożeniem kwaternionu $q$, wektora i~sprzężenie tego kwaternionu $q^{-1}$ (równania \ref{eq:q_4} i~\ref{eq:q_5}). 

\begin{samepage}
    \begin{equation}
        \label{eq:q_4}
        q^{-1} = \cos{\frac{\theta}{2}} - (u_xi+u_yj+u_zk)\sin{\frac{\theta}{2}}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$\theta$} kąt obrotu
        \item {$u$} wektor jednostkowy definiujący oś obrotu
        \item {$i, j, k$} jednostki urojone kwaternionu
    \end{eqexpl}
\end{samepage}

\begin{samepage}
    \begin{equation}
        \label{eq:q_5}
        v' = qvq^{-1}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$v'$} wektor obrócony
        \item {$q$} kwaternion definiujący obrót
        \item {$q^{-1}$} sprzężenie kwaternionu q
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}
Składanie obrotów w~przypadku zapisu macierzowego transformacji następuje poprzez ich pomnożenie. To samo ma miejsce w~przypadku kwaternionów, gdzie kolejność mnożenia decyduje o~odwrotnej kolejności złożenia obrotów.

\subsubsection{Obrót orbity}

Obrót orbity globalnej odbywa się relatywnie do pozycji kamery na orbicie lokalnej. W wyliczaniu osi obrotu muszą wziąć udział więc wektory obu orbit. Niech $\vv{g_{v}}$ i~$\vv{g_{up}}$ oraz $\vv{l_{v}}$ i~$\vv{l_{up}}$ będą wektorami orbit kolejno globalnej i~lokalnej zgodnymi z~rysunkiem \ref{fig:orbits}. Końcowy obrót orbity globalnej jest złożeniem obrotu w~kierunku pionowym i~poziomym relatywnym do widoku obserwatora. Osie tych obrotów wyrażają wektory:

\begin{samepage}
    \begin{align}
        \label{eq:o_1}
        \vv{h_g} &= \vv{l_{up}} \times \vv {l_{v}}\\
        \vv{v_g} &= \vv{l_{up}}
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\vv{h_g}$} oś obrotu zorientowana poziomo
        \item {$\vv{v_g}$} oś obrotu zorientowana pionowo
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Niech $\vv{d} \in \mathbb{R}^2 $ będzie przesunięciem widoku pochodzącym ze zdarzenia wygenerowanego przez użytkownika, wyrażonym w~pikselach. Współczynnik warunkujący kąt przesunięcia wyrażony jest wzorem:
\begin{samepage}
    \begin{equation}
        \label{eq:o_2}
        s = 0.001 \cdot G_s \cdot \Vert\vv{l_v}\Vert \cdot \Vert\vv{g_v}\Vert
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$G_s$} konfigurowany współczynnik obrotu orbity 
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Kąty obrotu wyrażone w~radianach wyrażone są wzorami:
\begin{samepage}
    \begin{align}
        \label{eq:o_3}
        \theta_x &= s \cdot d_x \\
        \theta_y &= s \cdot d_y
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\theta_x$} kąt obrotu w~osi pionowej, przesuwa widok w~osi $OX$
        \item {$\theta_y$} kąt obrotu w~osi poziomej, przesuwa widok w~osi $OY$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Niech $Q: (\mathbb{R}, \mathbb{R}^3) \to \mathbb{H}$ będzie funkcją konstruującą kwaternion na podstawie kąta i~osi obrotu wyrażoną wektorem jednostkowym. Kwaternion chwilowego obrotu orbity globalnej wyrażony jest wtedy wzorem \ref{eq:o_4}.

\begin{samepage}
    \begin{equation}
        \label{eq:o_4}
        q_g = Q(\theta_x, \frac{\vv{v}}{\Vert\vv{v}\Vert}) \cdot Q(\theta_y, \frac{\vv{h}}{\Vert\vv{h}\Vert})
    \end{equation}
    \vspace{\baselineskip}
\end{samepage}

Dla każdego zdarzenia przeciągnięcia widoku wygenerowane przez użytkownika dostarczany jest nowy wektor $\vv{d}$. Orbita globalna jest obracana na podstawie obliczonego kwaternionu $q_g$. Następnie zachodzi potrzeba korekcji owego obrotu związana z~trybem kamery i~ustawionymi ograniczeniami jej ruchu. 

\subsection{Obrót orbity lokalnej}
Obrót orbity lokalnej przebiega podobnie co obrót orbity globalnej. Zmianie ulegają wektory, które biorą udział w~wyznaczaniu osi obrotu orbity (równanie \ref{eq:o_5}) oraz współczynniki prędkości obrotu (równanie \ref{eq:o_6})).

\begin{samepage}
    \begin{align}
        \label{eq:o_5}
        \vv{h_l} &= \vv{l_{up}} \times \vv{l_{v}}\\
        \vv{v_l} &= [0, 0, 1]^T
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\vv{h_l}$} oś obrotu zorientowana poziomo
        \item {$\vv{v_l}$} oś obrotu zorientowana pionowo
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

W przypadku orbity lokalnej konieczne było rozdzielenie współczynników $s$ dla kierunku pionowego i~poziomego przesuwania. Obliczane są one według wzorów \ref{eq:o_6} i~\ref{eq:o_7}.

\begin{samepage}
    \begin{align}
        \label{eq:o_6}
        s_x &= -0.008 \cdot L_s \\
        \label{eq:o_7}
        s_y &= 0.004 \cdot L_s
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$L_s$} konfigurowany współczynnik obrotu orbity 
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Przyspieszenia mają inne znaki dlatego, że przeciągnięcie w~osi $OX$ skutkować musi obrotem kamery w~przeciwną stronę. Różne moduły współczynników mają na celu spowolnienie podnoszenia i~opuszczanie kamery względem obracania jej wokół punktu na powierzchni sfery. Z powodu tych zmian kąty obrotu obliczane są następująco:
\begin{samepage}
    \begin{align}
        \label{eq:o_8}
        \theta_x &= s_x \cdot d_x \\
        \theta_y &= s_y \cdot d_y
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\theta_x$} kąt obrotu w~osi pionowej, przesuwa widok w~osi $OX$
        \item {$\theta_y$} kąt obrotu w~osi poziomej, przesuwa widok w~osi $OY$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Tak jak w~przypadku orbity globalnej, końcowy kwaternion obrotu obliczany jest według wzoru \ref{eq:o_4}. Potem następuje korekcja obrotu związana z~ograniczeniami ruchu kamery zdefiniowanymi dla orbity lokalnej.

\subsection{Ograniczenia ruchu orbit}

\subsubsection{Obliczanie współrzędnych geograficznych na podstawie wektorów orbity.}
Powiązanie współrzędnych geograficznych z~orbitą ma sens tylko w~przypadku orbity globalnej, ponieważ reprezentuje ona obrót części ruchomej wizualizacji. Obie orbity jednak współdzielą ustawienia definiowane za pomocą owych współrzędnych.

Niech $P:\,(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^3$ będzie funkcją rzutującą wektor na płaszczyznę określoną jej wektorem normalnym i~normalizującą go, a~$A: \mathbb{H} \to \mathbb{R}$ funkcją ekstrahującą kąt obrotu z~kwaternionu. Niech $Q:(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{H}$ będzie funkcją konstruującą kwaternion obrotu na podstawie dwóch wektorów jednostkowych. Obliczenie długości i~szerokości geograficznej na podstawie wektorów orbity globalnej wyrażone jest wzorami \ref{eq:o_9} i~\ref{eq:o_10}.

\begin{samepage}
  \begin{align}
    q &= Q\Big(P(\vv{g_v}, \vv{g_{up}}), P([0, 0, 1]^T, \vv{g_{up}})\Big) \\
    \label{eq:o_9}
    long &= A(q) \cdot sgn([q_b, q_c, q_d]^T \cdot [0, 0, 1]^T) \\
    p &= Q\Big(P(\vv{g_{up}}, [0, 0, 1]^T), [0, 0, 1]^T\Big) \\
    \label{eq:o_10}
    lat &= A(p) \cdot sgn([0, 0, 1]^T \cdot \vv{g_{up}})
  \end{align}
\begin{eqexpl}[25mm]
    \item {$long$} długość geograficzna w~przedziale $\langle\ang{-180}; \ang{180}\rbrack$
    \item {$lat$} szerokość geograficzna w~przedziale $\langle\ang{-90}; \ang{90}\rbrack$
\end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Obliczenie długości i~szerokości geograficznej na podstawie wektorów orbity lokalnej wyrażone jest wzorami \ref{eq:o_11} i~\ref{eq:o_12}.

\begin{samepage}
  \begin{align}
    q &= Q\Big(P(\vv{l_v}, [0, 0, 1]^T), P([0, -1, 0]^T, [0, 0, 1]^T)\Big) \\
    \label{eq:o_11}
    long &= A(q) \cdot sgn([q_b, q_c, q_d]^T \cdot [0, 0, 1]^T) \\
    p &= Q\Big(P(\vv{l_{v}}, [0, 0, 1]^T), \vv{l_{v}}\Big) \\
    \label{eq:o_12}
    lat &= A(p) \cdot sgn([0, 0, 1]^T \cdot \vv{l_{v}})
  \end{align}
\begin{eqexpl}[25mm]
    \item {$long$} długość geograficzna w~przedziale $\langle\ang{-180}; \ang{180}\rbrack$
    \item {$lat$} szerokość geograficzna w~przedziale $\langle\ang{-90}; \ang{90}\rbrack$
\end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Ograniczenia pozycji sprowadza się do skonstruowania kwaternionu, który redukuje nadmiarowy obrót do ostatniej dozwolonej pozycji. Potrzebny obrót musi być złożeniem obrotów w~osiach długości i~szerokości geograficznej.
Dla orbity globalnej i~lokalnej osie te wyrażone są wektorami:
\begin{samepage}
  \begin{align}
      \vv{lat_g} &= [0, 0, 1]^T \times \vv{g_{up}} \\
      \vv{long_g} &= \vv{g_{up}} \\
      \vv{lat_l} &= \vv{l_{up}} \times \vv{l_v} \\
      \vv{long_l} &= [0, 0, 1]^T
  \end{align}
  \begin{eqexpl}[25mm]
      \item {$\vv{lat_g}$} oś obrotu orbity globalnej dla szerokości geograficznej
      \item {$\vv{long_g}$} oś obrotu orbity globalnej dla długości geograficznej
      \item {$\vv{lat_l}$} oś obrotu orbity lokalnej dla szerokości geograficznej
      \item {$\vv{long_l}$} oś obrotu orbity lokalnej dla długości geograficznej
  \end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Podczas korekty ruchu orbita jest obracana wokół wyliczonych osi o~kąt, który wynika z~różnicy pierwotnych współrzędnych i~współrzędnych ograniczających widok.

\subsection{Tryb kompasu}

Tryb kompasu dla orbity globalnej wymaga wykonania jeszcze jednego obrotu korekcyjnego. W momencie włączenia trybu kompasu zapisany zostaje wektor $\vv{c_n}$ wyliczony ze wzoru \ref{eq:compass_1}, który definiuje obecną orientację kierunku północnego.

Niech $P:\,(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^3$ będzie funkcją rzutującą wektor na płaszczyznę określoną jej wektorem normalnym. Wtedy:

\begin{samepage}
  \begin{equation}
    \label{eq:compass_1}
      \vv{c_n} = P(\vv{g_{up}}, \vv{l_v})
  \end{equation}
  \vspace{\baselineskip}
\end{samepage}



$Q:(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{H}$ jest funkcją konstruującą kwaternion obrotu na podstawie dwóch wektorów jednostkowych. Konstrukcja kwaternionu korekcji dla trybu kompasu kamery przedstawiona jest na równaniu \ref{eq:compass_2}.
\begin{samepage}
  \begin{equation}
    \label{eq:compass_2}
      q = Q\Big(\normalize{\vv c_n}, \normalize{\vv{lat_g}}\Big)
  \end{equation}
  \vspace{\baselineskip}
\end{samepage}

\subsection{Animacje - płynność ruchów}

Sterowanie kamerą jest przyjemniejsze w~odbiorze i~bardziej intuicyjne, jeśli poszczególne automatyczne operacja zmiany widoku są płynne, a~nie skokowe. Komponent Silnika obsługuje następujące animacje:
\begin{enumerate}
    \item Wytracanie prędkości obrotu orbity globalnej. Kiedy użytkownik zwolni przycisk myszy podczas obracania widoku, ruch nie zatrzymuje się od razu.
    \item Animacja przybliżania i~oddalania kamery.
    \item Orientowanie kamery w~kierunku północnym.
\end{enumerate}

Animacje posiadają konfigurowalny czas trwania i~w celu wyliczenia pozycji pośredniej orbit korzystają z~interpolacji liniowej i~sferycznej\cite{Slerp} wektorów (równanie \ref{eq:q_1}).
\begin{samepage}
    \begin{equation}
      \label{eq:q_1}
        Slerp (q_0, q_1, t) = q_0(q_0^{-1} q_1)^t
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$q_0$} kwaternion początkowy
        \item {$q_1$} kwaternion końcowy
        \item {$t$} postęp interpolacji w~przedziale $\lbrack0;1\rbrack$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}
\begin{multicols}{2}
    
    Postęp interpolacji $t$ modyfikowany jest przez konfigurowalną funkcję wygładzającą \mbox{$f: X \to Y$} gdzie \mbox{$X, Y \in \lbrack0;1\rbrack$}. Domyślnie używaną funkcją jest \textit{cubicOut}, której wzór i~wykres przedstawiony jest na rysunku \ref{fig:ease_1}.
    
    \columnbreak

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=0.7]
            \begin{axis}[domain=0:1,xmin=0,xmax=1.1,ymin=0,ymax=1.1,xlabel=$t$, ylabel=$f(t)$, legend pos=south east]
                \addplot[blue, ultra thick] {1-(1-x)^3)};
                \addlegendentry{$f(t) = 1 - (1-t)^3$};
            \end{axis}
        \end{tikzpicture}
        \caption{Funkcja wygładzająca \textit{cubicOut}}
        \label{fig:ease_1}
    \end{figure}
    
\end{multicols}

\subsection{Macierze transformacji obiektów na podstawie orbit}

Niech $T : \mathbb{R}^3 \to \mathbb{R}^{4\times4}$ będzie funkcją konstruującą macierz translacji na podstawie wektora w~przestrzeni trójwymiarowej. Niech $R : (\mathbb{R}^3, \mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^{4\times4}$ będzie funkcją konstruującą macierz obrotu obserwatora, aby patrzył na dany punkt w~odpowiedniej orientacji. Macierz transformacji grupy obrotu, czyli ruchomej części wizualizacji, wyrażona jest równaniem \ref{eq:t_1}. Macierz transformacji obiektu kamery wyrażone jest równaniem \ref{eq:t_2}.

\begin{align}
    \label{eq:t_1}
      M_g &= T([0, 0, -\Vert\vv{g_v}\Vert]^T) \cdot R([0, 0, 0]^T, -\vv{g_v}, \vv{g_{up}}) \\
    \label{eq:t_2}
      M_l &= T(\vv{l_v}) \cdot R(\vv{l_v}, [0, 0, 0]^T, \vv{l_{up}})
\end{align}

\section{Implementacja}

Komponent Silnika zaimplementowany został w~języku TypeScript\cite{TypeScript}. Jest on nadzbiorem języka JavaScript i~umożliwia korzystanie ze statycznego typowania, które w~JavaScripcie nie jest możliwe. Udostępnia tworzenie unii typów, zawiera mechanizmy ich inferencji. Wprowadza wzorzec dekoratorów, zawiera obsługę formatu JSX i~dodaje zmienne wyliczeniowe. Rozszerza możliwości programowania obiektowego o~typy generyczne. Przed uruchomieniem musi być transpilowany do języka JavaScript. Walidacja utworzonego kodu pod względem poprawności typowania następuje w~momencie transpilacji i~nie jest dokonywana podczas jego wykonywania. 

Zaletą stosowania statycznego typowania jest zniw elowanie możliwości pomyłek programisty związanych z~nieznajomością interfejsów używanych klas i~modułów. Statycznie typowany kod sam w~sobie stanowi źródło swojej dokumentacji, a~mechanizmy refleksji pozwalają na jeszcze bardziej rozległą walidację typów i~dynamiczne generowanie dokumentacji.

Systemu wizualizacji danych geograficznych jako całość nazwany został \textit{GeoVis}, co jest skrótem wyrażenia \textit{\textbf{Geo}graphic \textbf{Vis}ualization}. Komponent Silnika przyjął nazwę \mbox{\textit{GeoVisEngine}} i~składa się z~modułu \mbox{\textit{GeoVisCore}}, który osadzony jest w~eksportowanym komponencie \mbox{\textit{GeoVisCoreVue}}. Relację pomiędzy ogólnymi komponentami przedstawiona jest na diagramie~\ref{fig:c3_geo_vis_engine}. Kod silnika podzielony został na domeny, które realizują zadania według odkreślonej odpowiedzialności. Są to:

\begin{enumerate}
    \item \texttt{Animation} - obsługuje animacje, udostępnia mechanizmy definiowania transformacji pomiędzy dwoma obiektami z~użyciem wybranej funkcji wygładzającej i~zdefiniowanym czasem.
    \item \texttt{Camera} - zarządza ruchami kamery, udostępnia interfejs \texttt{TrackballCamera} dostępny od strony wizualizacji.
    \item \texttt{GeoPosition} - zawiera definicję obiektów orbit i~współrzędnych geograficznych. Odpowiedzialna jest również za transformacje pomiędzy współrzędnymi geograficznymi, a~trójwymiarową sceną.
    \item \texttt{Utils} - zawiera funkcje pomocnicze.
    \item \texttt{Visualization} - zawiera klasy bazowe definiujące wizualizację oraz ich przykłady.
\end{enumerate}

\begin{figure}
    \centering 
    \includegraphics[scale=0.6]{diagrams/out/c3_geo_vis_engine.png}
    \caption{Zależności głównych komponentów Silnika}
    \label{fig:c3_geo_vis_engine}
\end{figure}

\subsection{GeoVisCore}

\textit{GeoVisCore} jest komponentem odpowiedzialnym za dostarczenie elementu \texttt{Canvas}, który następnie osadzony jest w~komponencie \textit{GeoVisCoreVue} opisanym w dalszej części pracy. \textit{GeoVisCore} obsługuje zdarzenia wygenerowane przez użytkownika pochodzące z~elementu \texttt{Canvas}. Zdarzeniami tymi są te, związane z myszką i klawiaturą. Komponent realizuje cykl życia wizualizacji, wyświetlając opisane przez nią obiekty i~propagując zdarzenia pochodzące od użytkownika. To w~tym komponencie osadzone jest środowisko biblioteki Three.js.
W opisie implementacji najpierw zostanie przedstawiona struktura i~zależności każdej z~klas i~komponentów, a~następnie opisany zostanie cykl życia wizualizacji.

Klasa \texttt{GeoVisCore}, której despośrednie zależności przedstawia diagram \ref{fig:c3_geo_vis_core}, jest głównym elementem komponentu Silnika. Inicjalizuje one zależności ekosystemu biblioteki Three.js, odpowiada za obsługę elementu \texttt{Canvas} oraz za uruchamianie i~aktualizowanie wizualizacji. Sterowanie wyświetlaną wizualizacją odbywa się za pomocą metody \mbox{\texttt{GeoVisCore.run(v: Visualization)}}. Przy kolejnych jej wywołaniach instancje obiektów starej wizualizacji są usuwane. Ma to miejsce również podczas wywołania metody \mbox{\texttt{GeoVisCore.destroy()}}, która powoduje wyjście z głównej pętli animacji i zamknięcie instancji komponentu.

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_geo_vis_core.png}
    \caption{Diagram klas dla klasy \texttt{GeoVisCore}}
    \label{fig:c3_geo_vis_core}
\end{figure}

Najważniejszą klasą, odpowiedzialną za sterowanie kamerą, jest klasa \texttt{TrackballController}. Implementuje ona interfejs \texttt{TrackballCamera}, który definiuje metody sterowania kamerą dostępne dla twórcy wizualizacji. Diagram najważniejszych zależności klasy \texttt{TrackballController} pokazano na rysunku \ref{fig:c3_trackball}. W celu zachowania czytelności, na diagramie nie uwzględniono metod i atrybutów klas in interfejsów.

Ze względów bezpieczeństwa kod wykonujący się w przeglądarce nie ma dostępu do niczego, poza obsługiwaną stroną. Wykonuje się on również tylko na jednym wątku, aby uniknąć typowych problemów programów wielowątkowych takich jak wyścigi czy trudniejsze zarządzenie i współdzielenie pamięci. W typowych przypadkach aplikacje webowe przez większość czasu są bezczynne i większość kodu, który wykonuje się na stronie, wyzwalany jest za pomocą zdarzeń wysyłanych przez przeglądarkę. Dlatego JavaScript opiera swoje działania na tak zwanym EventLoop. Jest to pętla, która, w dużym uproszczeniu, obsługuje zdarzenia z określonym priorytetem, kładąc nacisk na responsywność interfejsu użytkownika. Przykładem takich zdarzeń może być naciśnięcie przycisku myszy, ale też żądanie wygenerowanie klatki animacji. Wszystko sprowadza się do asynchronicznego wykonania zdefiniowanej procedury obsługi takiego zdarzenia. JavaScript definiuje zaimplementowany w obiektach DOM interfejs EventTarget\cite{JsEvents}, który umożliwia zdefiniowanie funkcji wykonywanej po zajściu zdarzenia. Zdarzenia identyfikowane są jako ciąg znaków. Wykorzystując przewagę języka TypeScript możemy tworzyć, emitować i obsługiwać zdarzenia, gdzie każdy aspekt będzie posiadał statyczne typowanie. W tym celu wykorzystano bibliotekę o nazwie \texttt{strongly-typed-events}\cite{Events} implementującą to podejście. Interface \texttt{TrackballCamera} korzysta z interfejsu \texttt{IEvent} dostarczonego przez tę bibliotekę (diagram \ref{fig:c3_trackball}). Różnica pomiędzy obsługą zdarzeń w JavaScripcie i z możliwościami TypeScriptu przedstawiają listingi \ref{lst:events_1} i \ref{lst:events_2}.

\begin{lstlisting}[language=javascript, label={lst:events_1}, caption={Obsługa zdarzenia w języku JavaScript}]
const event = new Event('event');
event['payload'] = "testData";
elem.addEventListener('event', (data) => {
    console.log(data.payload) 
}, false);

elem.dispatchEvent(event); // prints: testData
\end{lstlisting}

\begin{lstlisting}[language=javascript, label={lst:events_2}, caption={Obsługa zdarzenia w języku TypeScript z wykorzystaniem biblioteki \texttt{strongly-typed-events}}]
const onEvent = new SimpleEventDispatcher<{payload: string}>();
onEvent.asEvent().sub((data) => {
    console.log(data.payload); 
})

onEvent.dispatch({payload: 'testData'});  // prints: testData
\end{lstlisting}

\texttt{TrackballController} realizuje operacje obrotów orbit opisane w~rozdziale \ref{sec:camera}. Orbity reprezentowane są przez obiekty \texttt{GlobalOrbit} i~\texttt{LocalOrbit} dziedziczące po klasie \texttt{Orbit}, które realizuje wspólne operacja dla obu z~nich. Są to między innymi wykonywanie obrotów korekcyjnych dla pozycji kamery i~orientacji w~kierunku północnym. Wspólną funkcjonalność różni układ odniesienia obu orbit i~dlatego wydzielono metody abstrakcyjne klasy \texttt{Orbit}. Jej klasy pochodne implementują je inaczej, zwracając różne wektory. Klasa \texttt{AnimatedTransition} reprezentuje animację pojedynczego obiektu. Zawiera ona swój własny zegar i~pozwala zdefiniować długość oraz funkcję wygładzającą.

Ukrycie faktycznej implementacji kontrolera kamery za interfejsem \texttt{TrackballCamera} daje późniejszą możliwość zastąpienia jej inną. Realizując ten sam interfejs, nie będzie ona wpływać na już utworzone wizualizacje i~pozostałą część aplikacji. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{diagrams/out/c3_trackball.png}
    \caption{Diagram klas dla klasy \texttt{TrackballController} i~najważniejszych zależności}
    \label{fig:c3_trackball}
\end{figure}

\section{Podsumowanie}