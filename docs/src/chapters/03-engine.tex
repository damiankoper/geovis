\chapter{Silnik}

Rozdział ten opisuje główny komponent tworzonego systemu nazwanego Silnikiem. Odpowiedzialny jest on za dostarczenie interfejsu definiowania trójwymiarowej wizualizacji i~jej późniejsze wyświetlanie. Narzuca również sposób pracy kamery i~umożliwia konfigurację jej parametrów.

Wszystkie obiekty wyświetlane na scenie, razem z~definicją ich wyglądu, tekstur i~dynamiki ruchów dostarcza wizualizacja. Jej obiekty mogą reagować na zdarzenia, które generuje użytkownik. Wywołanie zdefiniowanych procedur obsługi tych zdarzeń również leży w gestii komponentu Silnika.

Najpierw w~sposób uproszczony opisany zostanie sposób renderowania grafiki z~wykorzystaniem API WebGL oraz biblioteki Three.js. Następnie przedstawione zostaną mechanizmy sterujące pracą kamery, a~następnie implementacja komponentu Silnika i~opisanych mechanizmów.

\section{WebGL i~ESSL}

WebGL jest dostępnym z~poziomu języka JavaScript API pozwalającym na renderowanie grafiki trójwymiarowej w~przeglądarce. Złożone obiekty rysowane są tylko za pomocą punktów, linii i~trójkątów.  WebGL działa w~trybie \textit{immidiate}, który to wymusza na aplikacji wykonywanie bezpośrednio niskopoziomowych komend rysujących podstawowe obiekty 3D. Aplikacja korzystająca z~WebGL musi sama definiować abstrakcje podstawowych obiektów takich jak scena, kamera, czy światło. Podejście to jest bardzo elastyczne i~pozwala na optymalizację implementowanych rozwiązań w~zależności od potrzeb\cite[Rozdział 1]{RealTime3DGraphics}. WebGL korzysta z~akceleracji sprzętowej podczas renderowania grafiki - działa na GPU. W przypadku kart graficznych bez wsparcia dla tej technologii przeglądarki Google Chrome i~Internet Explorer 11 umożliwiają rysowanie z~użyciem CPU.

Drugim podejściem do renderowania grafiki jest podejście \textit{retained}, gdzie biblioteki z~niego korzystające implementują swoją abstrakcję sceny i~same zajmują się jej rysowaniem. Przykładem takiej biblioteki jest Windows Presentation Foundation\cite{WPF}.

Dostęp do API WebGL uzyskać można poprzez kontekst elementu \texttt{Canvas}. Na listingu \ref{lst:webglContext} pokazano pobranie kontekstu API WebGL do zmiennej \texttt{gl}. Wszystkie interakcje związane z~użyciem API będą odbywały się z~użyciem pobranego obiektu kontekstu. Numer w~identyfikatorze \texttt{’webgl2’} mówi, że używamy WebGL w~wersji drugiej.

\begin{lstlisting}[language=javascript, label={lst:webglContext}, caption={Pobranie kontekstu API WebGL do zmiennej}]
const canvas = document.getElementById('vis-container');
const gl = canvas.getContext('webgl2');
\end{lstlisting}

Obiekt kontekstu działa jak maszyna stanów. Przechowuje ustawiony stan do czasu jego zmiany przez aplikację. Wszystkie operacje renderowania grafiki korzystają z~globalnie ustawionych parametrów, które definiują stan kontekstu i~mają bezpośredni wpływ na efekt końcowy\cite[Rozdział 1]{RealTime3DGraphics}.

\subsubsection{Rysowanie sceny}

Rysowanie obiektu rozpoczyna się od utworzenia buforów danych i~umieszczenia w~nich współrzędnych wierzchołków oraz kolejności, według której wierzchołki mają brać udział w~procesie rysowania. Kolejność ma istotne znaczenie w~przypadku różnych trybów rysowania oraz, Cullingu czyli określania widocznej strony rysowanego trójkąta. Bufory są reprezentowane zewnętrznie jako tablice \texttt{TypedArray}. Przechowują one jedynie surowe dane w~postaci binarnej~\cite{TypedArrays}. W języku JavaScript występuje jeden typ \texttt{number} przechowujący liczby, które wewnętrznie reprezentowane są jako 64b liczba zmiennoprzecinkowa. Dodatkowo każda zmienna numeryczna jest obiektem typu \texttt{Number} z~własnymi metodami. Użycie buforów z~interfejsem tablicy przyspiesza masowe operacje na danych.

\subsubsection{Shadery}

W WebGL'u \textit{programem} nazywane są skompilowane przez kontekst shadery. Są to krótkie programy napisane w~specjalistycznym języku, którym w~przypadku WebGL'a jest ESSL~(ang.~OpenGL ES Shading Language). Przypomina on składnią język C/C++~\cite{ESSL} i~zawiera wbudowane funkcje wymagane do operacji matematycznych takich jak iloczyn skalarny wektorów, czy mnożenie macierzy. Na wspomniany \textit{program} składają się dwa podprogramy (shadery) - \texttt{vertex shader} i~\texttt{fragment shader}. \texttt{Vertex shader}, uruchamiany jako pierwszy, pobiera dane o~wierzchołkach z~buforów, oraz korzystając ze stałych (\texttt{uniforms}) oblicza finalną pozycję wierzchołka. W większości przypadków shader ten odpowiada również za obliczenie innych parametrów wierzchołka takich jak kolor, jego wektor normalny, czy też współrzędne tekstur. Dla każdego wierzchołka wyliczone wartości wysyłane są dalej do shadera \texttt{fragment shader}.

\texttt{Fragment shader} odpowiada za wyliczenie koloru pojedynczego pixela. Dane wysłane z~\texttt{vertex shader}'a w~zmiennych typu \texttt{varying} są automatycznie interpolowane dla każdego punktu w~renderowanym trójkącie na podstawie trzech wierzchołków.

W shaderach, po dostarczeniu odpowiednich danych, realizowane są abstrakcje takie jak kamera, oświetlenie, czy materiały.

\subsubsection{Obliczanie finalnej pozycji wierzchołków}

W grafice 3D każdy model reprezentowany jest przez zbiór punktów i~informacji o~kolejności ich rysowania. Model może mieć swoją pozycję w~świecie 3D, a~obserwator może znajdować się w~różnych miejscach sceny. WebGL sam w~sobie nie posiada abstrakcji kamery i~do wyświetlenia sceny z~konkretnej perspektywy konieczne jest przemieszczenie wszystkich wierzchołków geometrii. Transformacja pozycji wierzchołków odbywa się za pomocą przekształceń afinicznych, które transformują pozycję zbioru wierzchołków i~nie zaburzają relacji przestrzennych pomiędzy nimi. Efektywnie transformacja taka jest mnożeniem macierzy transformacji o~wymiarach 4x4 i~wektora z~dodaną czwartą współrzędną równą 1, co daje nowy wektor współrzędnych wierzchołka.

Przekształcenia związane z~pozycją modelu i~kamery w~świecie wyrażane są za pomocą macierzy. Macierzowy opis przekształceń możliwy jest dzięki zastosowaniu współrzędnych jednorodnych\cite{Homogeneous}. Transformacja pozycji modelu odbywa się z~pomocą macierzy $M$, a~transformacja pozycji związana z~położeniem kamery z~pomocą macierzy widoku $V$. Wyliczanie współrzędnych wierzchołka w~układzie współrzędnych świata pokazano w~równaniu \ref{eq:MV}.

Aby uzyskać wyjściową pozycję piksela na ekranie konieczne jest pomnożenie macierzy projekcji i~wektora pozycji wierzchołka w~układzie współrzędnych świata (równanie \ref{eq:MVP}). Macierz projekcji odpowiada za transformację współrzędnych wierzchołka do sześcianu o~wymiarach 2x2x2 i~środku w~punkcie $(0, 0, 0)$. Transformacja ta może być perspektywiczna, gdzie przekształceniu ulega przestrzeń w~kształcie ostrosłupa ściętego. Może być też ortograficzna, gdzie przekształceniu ulega przestrzeń w~kształcie prostopadłościanu. Punkty leżące poza tą przestrzenią nie są rysowane. Współrzędne $(x, y)$ transformowanych wierzchołków są współrzędnymi \textit{NDC} (ang. Normalized Device Coordinates), niezależnymi od urządzenia. Dzięki temu mogą być one łatwo przekształcone na piksele elementu \texttt{Canvas}, gdzie punkt $(0, 0)$ znajduje się w~lewem górnym rogu. Podejście to uniezależnia generowanie pikseli od elementu wyświetlającego, do którego trzeba dostosować tylko sposób przekształcenia współrzędnych \textit{NDC}.

\begin{equation}
    \label{eq:MV}
    p' = VM \cdot \begin{bmatrix}
        p_{1} \\
        p_{2} \\
        p_{3} \\ 
        1
      \end{bmatrix}
\end{equation}
\begin{eqexpl}[25mm]
    \item{$M$} macierz transformacji pozycji modelu
    \item{$V$} macierz transformacji widoku
    \item{$p'$} wektor pozycji wierzchołka w~układzie współrzędnych widoku
    \item{$p$} wektor pozycji modelu w~układzie współrzędnych świata
\end{eqexpl}

\begin{equation}
\label{eq:MVP}
    v = P \cdot \begin{bmatrix}
        p'_{1} \\
        p'_{2} \\
        p'_{3} \\ 
        1
      \end{bmatrix}
\end{equation}
\begin{eqexpl}[25mm]
    \item{$P$} macierz projekcji
    \item{$p'$} wektor pozycji wierzchołka w~układzie współrzędnych widoku
\end{eqexpl}
\vspace{\baselineskip}
Kalkulacja pozycji modeli oraz kamery ma szczególne znaczenie przy złożonym zachowaniu kamery oraz sceny w~komponencie Silnika.

\subsection{Three.js}

Three.js\cite{threejs} jest biblioteką 3D, która domyślnie do renderowania grafiki używa WebGL. Ułatwia ona rozpoczęcie pracy z~grafiką 3D i~jednocześnie nie nakłada ograniczeń związanych z~niskopoziomową konfiguracją wyświetlanej sceny. Pozwala ona na opisanie sceny, obiektów, świateł i~materiałów w~postaci obiektowej. Posiada rozbudowany system animacji oraz wsparcie dla systemów wirtualnej rzeczywistości. Na listingu \ref{lst:threejs:base} pokazano kod aplikacji, która wyświetla zielony sześcian.

\begin{lstlisting}[float=h,language=javascript, label={lst:threejs:base}, caption={Hello World w~świecie grafiki 3D}]
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera( 75, window.innerWidth / window.innerHeight, 0.1, 1000 );
    
    const renderer = new THREE.WebGLRenderer();
    renderer.setSize( window.innerWidth, window.innerHeight );
    document.body.appendChild( renderer.domElement );

    const geometry = new THREE.BoxGeometry();
    const material = new THREE.MeshBasicMaterial( { color: 0x00ff00 } );
    const cube = new THREE.Mesh( geometry, material );
    scene.add( cube );

    camera.position.z = 5;

    function animate() {
        requestAnimationFrame( animate );
        renderer.render( scene, camera );
    }
    animate();
\end{lstlisting}

Na początku tworzony jest obiekt sceny, która jest kontenerem na pozostałe wyświetlane obiekty oraz światła. Następnie tworzony jest obiekt kamery, który definiuje właściwości, w~tym wypadku, projekcji perspektywicznej. Utworzony dalej obiekt \texttt{THREE.WegGLRenderer} odpowiedzialny jest za utworzenie i~przechowywanie referencji do obiektu \texttt{Canvas}, na którym, w~głównej pętli programu, rysuje dostarczoną scenę z~perspektywy wybranej kamery. Odpowiada za to wywołanie \texttt{renderer.render(scene, camera)}.

Geometrię kostki definiuje obiekt \texttt{THREE.BoxGeometry}, która z~domyślnymi argumentami konstruktora jest sześcianem o~wymiarach 1x1x1. Obiekt ten posiada atrybuty ułatwiające zarządzanie wygenerowaną geometrią. Zwykłe obiekty geometrii są konwertowane do typu \texttt{BufferGeometry} w~procesie renderowania, Wtedy dane wierzchołków są umieszczane w~buforach, które mogą być bezpośrednio wykorzystane w~interakcji z~WebGL'em. Three.js pozwala tworzyć geometrię w~sposób bardziej efektywny, jednak gorzej zarządzalny, wykorzystując klasy pochodne klasy \texttt{BufferGeometry}, takie jak \texttt{BoxBufferGeometry}.

Elementy wyglądu rysowanych geometrii określa materiał. W Three.js obiektami je reprezentujące są pochodne klasy \texttt{Material}. Umożliwiają ustawienie koloru, tekstur, różnego rodzaju map, a~w przypadku światła parametry jego interakcji z~powierzchnią obiektu. W procesie rysowania obiektu, atrybuty jego materiału, oraz atrybuty obiektów ważnych dla wyglądu rysowanego obiektu, na przykład świateł, są wysyłane do shaderów w~postaci stałych (\texttt{uniforms}). Sam materiał definiuje jednoznacznie działanie shaderów, wykorzystanych w~procesie jego rysowania. Przykład shadera dla materiału \texttt{MeshBasicMaterial} pokazano na listingu \ref{lst:matVert}.

\begin{lstlisting}[language=C++, label={lst:matVert}, caption={
    Fragmenty vertex shadera materiału \texttt{MeshBasicMaterial}}
]
#include <common>
/* ... */

void main() {
    /* ... */
	#include <color_vertex>
    /* ... */

	#include <begin_vertex>
	/* ... */
	#include <project_vertex>
	/* ... */
}
\end{lstlisting}

Shadery różnych materiałów współdzielą pomiędzy sobą wiele swoich części. Zastosowana dyrektywa \texttt{\#include} pozwala na umieszczenie w~kodzie wspólnych ich części. Na listingu \ref{lst:vertProject}, w~części \texttt{project\_vertex}, widać właściwy proces obliczania pozycji wierzchołka przedstawiony na równaniach \ref{eq:MV} i~\ref{eq:MVP}. Macierz projekcji mnożona jest przez połączoną macierz modelu i~widoku oraz zmienną wektorową \texttt{mvPosition}. Wynikowy wektor wpisywany jest do specjalnej zmiennej globalnej \texttt{gl\_Position}, której zawartość informuje resztę składowych procesu generowania grafiki o~wyniku kalkulacji. 

\begin{lstlisting}[language=C++, label={lst:vertProject}, caption={
    Fragmenty części \texttt{project\_vertex} vertex shadera}
]
vec4 mvPosition = vec4( transformed, 1.0 );
/* ... */
mvPosition = modelViewMatrix * mvPosition;
gl_Position = projectionMatrix * mvPosition;
\end{lstlisting}

Three.js dostarcza również wiele narzędzi ułatwiających operacje matematyczne na wektorach oraz macierzach. Pozwala między innymi na interpolację liniową i~sferyczną wektorów, generowanie macierzy transformacji, czy reprezentowanie obrotów za pomocą kątów Eulera lub kwaternionów.

\section{Praca kamery}
\label{sec:camera}

Komponent Silnika wyświetla scenę, w~której kamera orbituje wokół jednego punktu. Dodatkowo użytkownik może zmienić orientację kamery względem punktu na powierzchni sfery. Opis pracy kamery odnosić się będzie do obiektu sfery i~jej powierzchni, jednak nic nie stoi na przeszkodzie, aby kamera orbitowała wokół innego obiektu. W tym podrozdziale opis mechanizmów jest przedstawiony w~oderwaniu od ich implementacji w~projekcie. Finalnie, pozycję kamery relatywnie do środka sfery opisują dwie orbity. Orbitą, w~kontekście pracy kamery, nazwana została para wektorów określająca obrót od wektora odniesienia i~odległość od punktu jego zaczepienia.

Wspomniane orbity nazwano orbitą lokalną i~orbitą globalną. Orbita globalna odpowiedzialna jest za pozycję kamery nad punktem obiektu sfery. Orbita lokalna określa orientację kamery względem punktu, nad którym się znajduje. Taki podział sceny wprowadza również dwa układy odniesienia.

\begin{enumerate}
    \item Układ obserwatora - układ, w~którym znajduje się obserwator i~wszystkie obiekty są pozycjonowane relatywnie do obiektu kamery. Jest to domyślny układ renderowanej sceny.
    \item Układ wizualizacji - układ, w~którym obiekty pozycjonowane są relatywnie do mogącej obracać się sfery. Obiekty umieszczane są w~obracającej się grupie.
\end{enumerate}

Żeby przybliżyć zależności pomiędzy tymi układami, można posłużyć się przykładem. Aby symulować cykl dnia i~nocy, światło musi być pozycjonowane w~układzie wizualizacji, ponieważ jest niezależne od ruchu kamery. Aby światło oświetlało zawsze widoczną stronę planety, musi być ono pozycjonowane w~układzie obserwatora. Ogólny graf sceny przedstawiono na diagramie~\ref{fig:c3_scene_graph}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_scene_graph.png}
    \caption{Ogólny graf sceny wizualizacji}
    \label{fig:c3_scene_graph}
\end{figure}

\subsection{Orbita globalna}

Orbitę globalną definiują dwa wektory - $\vv{g_v}$ i~$\vv{g_{up}}$ na rysunku \ref{fig:orbits}. Pierwszy rozciągnięty jest od środka $s$ sfery do punktu $c_g$, wokół którego orbituje kamera. Drugi jest wektorem jednostkowym do niego prostopadłym określającym orientację sfery w~osi pierwszego wektora. W późniejszym opisie działanie \textit{na orbicie}, na przykład obrót orbity, oznacza wykonanie tej samej transformacji na obu wektorach. W ten sposób oba wektory nigdy nie zmienią swojej wzajemnej orientacji.

Użytkownik za pomocą myszy lub klawiatury może obrócić sferę, a~konkretnie grupę obrotu (\texttt{OrbitGroup} na diagramie \ref{fig:c3_scene_graph}) i~zawierane przez nie obiekty. Jest to efektywnie zmianą punktu, nad którym znajduje się kamera, pomimo tego, że jej pozycja się nie zmienia. Jako, że obrót sfery definiowany jest abstrakcję orbity, cała operacja sprowadza się do jej odpowiedniego obrócenia. 
\begin{samepage}
Parametrami specyficznymi dla orbity globalnej są:
\begin{enumerate}
    \item Tryb pracy orbity - określa czy podczas przesuwania orbity ma ona zachowywać swoją orientację w~kierunku północnym. Wydzielono tryb \textit{swobodny} i~\textit{kompas}.
\end{enumerate}
\end{samepage}
\subsection{Orbita lokalna}

Orbitę lokalną, podobnie jak globalną, definiują dwa wektory - $\vv{l_v}$ i~$\vv{l_{up}}$ na rysunku \ref{fig:orbits}. Pierwszy rozciągnięty jest od punktu $c_g$, wokół którego orbituje kamera, do kamery (punkt $c_l$). Drugi jest wektorem jednostkowym do niego prostopadłym określającym orientację kamery w~osi pierwszego wektora.

Użytkownik za pomocą myszy lub klawiatury może zmienić punkt orbitowania kamery. Jest to efektywnie zmianą położenia kamery w~układzie obserwatora. Jako, że pozycja kamery definiowany jest przez abstrakcję orbity, cała operacja sprowadza się do jej odpowiedniego obrócenia. Długość wektora $\vv{l_v}$ reprezentuje odległość obserwatora do punktu na powierzchni sfery. 

Parametrami specyficznymi dla orbity lokalnej są:
\begin{enumerate}
    \item współczynnik przybliżenia - jak powinna zmienić się odległość kamery od punktu na powierzchni sfery podczas jednej akcji przybliżenia.
    \item granice przybliżenia - minimalna i~maksymalna odległość kamery od punktu na powierzchni sfery.
\end{enumerate}

\subsection{Parametry wspólne dla obu orbit}

Dla obu orbit wyróżniono wspólne parametry. Są nimi:
\begin{enumerate}
    \item granice - wyrażony w~radianach zakres współrzędnych geograficznych definiujący fragment sfery, nad którym kamera może się znaleźć. Może służyć na przykład do ograniczenia obszaru poruszania się użytkownika tylko do jednej półkuli lub jednego miasta.
    \item prędkość obrotu - współczynnik sterujący prędkością obrotu danej orbity.
\end{enumerate}

Wszystkie parametry, ogólne i~te specyficzne dla każdej z~orbit mogą być konfigurowane przez wizualizację.

\begin{figure}[]
    \centering
    \input{drawings/orbits.tex}
    \caption{Schemat orbit w~specyficznym przypadku dwóch wymiarów}
    \label{fig:orbits}
\end{figure}



\subsection{Obrót orbity globalnej}

Algorytm obrotu orbity globalnej wykonywany jest dla każdego zdarzenia przesunięcia myszy użytkownika podczas gestu chwycenia, przeciągnięcia i~upuszczenia wygenerowanym przez element \texttt{Canvas}. Obrót wymaga obliczenia jego chwilowej osi i~kąta.

\subsubsection{Kwaterniony}
Kwaterniony są rozszerzeniem liczb zespolonych \cite{Quaternions}. Mają one postać:
\begin{equation}
    \label{eq:q_1}
    q = a~+ bi + cj + dk : a,\,b,\,c,\,d\in\mathbb{R}
\end{equation}
gdzie, podobnie jak w~przypadku liczb zespolonych, zachodzi zależność:
\begin{equation}
    \label{eq:q_2}
    i^2 = j^2 = k^2 = ijk =  -1
\end{equation}

Ich mnożenie następuje, z~uwzględnieniem zależności z~równania \ref{eq:q_2}, tak jak mnożenie wielomianów.

Kwaternion może być interpretowany jak suma skalaru z~wektorem, gdzie współczynnik $a$~jest skalarem, a~$b$, $c$ i~$d$ są współrzędnymi wektora. Kwaterniony jednostkowe służą między innymi do reprezentacji obrotów w~przestrzeni 3D. Rozwiązują one problemy związane z~reprezentacją obrotów poprzez kąty Eulera. Obrót taki jest zdefiniowany poprzez obroty wokół każdej z~osi układu współrzędnych. Obracanie z~ich użyciem, w~pewnym kombinacjach obrotu może skutkować efektem gimbal-lock, który powoduje zanikiem stopnia swobody obrotu. Dlatego w~tym przypadku ważna jest kolejność obrotów. Stosując kąty Eulera niemożliwa jest bezpośrednia interpolacja sferyczna pomiędzy dwoma zdefiniowanymi obrotami.

Konstrukcja kwaternionu definiującego dany obrót jest następująca:
\begin{samepage}
    \begin{equation}
        \label{eq:q_3}
        q = \cos{\frac{\theta}{2}} + (u_xi+u_yj+u_zk)\sin{\frac{\theta}{2}}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$\theta$} kąt obrotu
        \item {$u$} wektor jednostkowy definiujący oś obrotu
        \item {$i, j, k$} jednostki urojone kwaternionu
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Obrót wektora jest sprowadzeniem wektora do kwaternionu ze współczynnikiem $a = 0$ i~pomnożeniem kwaternionu $q$, wektora i~sprzężenie tego kwaternionu $q^{-1}$ (równania \ref{eq:q_4} i~\ref{eq:q_5}). 

\begin{samepage}
    \begin{equation}
        \label{eq:q_4}
        q^{-1} = \cos{\frac{\theta}{2}} - (u_xi+u_yj+u_zk)\sin{\frac{\theta}{2}}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$\theta$} kąt obrotu
        \item {$u$} wektor jednostkowy definiujący oś obrotu
        \item {$i, j, k$} jednostki urojone kwaternionu
    \end{eqexpl}
\end{samepage}

\begin{samepage}
    \begin{equation}
        \label{eq:q_5}
        v' = qvq^{-1}
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$v'$} wektor obrócony
        \item {$q$} kwaternion definiujący obrót
        \item {$q^{-1}$} sprzężenie kwaternionu q
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}
Składanie obrotów w~przypadku zapisu macierzowego transformacji następuje poprzez ich pomnożenie. To samo ma miejsce w~przypadku kwaternionów, gdzie kolejność mnożenia decyduje o~odwrotnej kolejności złożenia obrotów.

\subsubsection{Obrót orbity}

Obrót orbity globalnej odbywa się relatywnie do pozycji kamery na orbicie lokalnej. W wyliczaniu osi obrotu muszą wziąć udział więc wektory obu orbit. Niech $\vv{g_{v}}$ i~$\vv{g_{up}}$ oraz $\vv{l_{v}}$ i~$\vv{l_{up}}$ będą wektorami orbit kolejno globalnej i~lokalnej zgodnymi z~rysunkiem \ref{fig:orbits}. Końcowy obrót orbity globalnej jest złożeniem obrotu w~kierunku pionowym i~poziomym relatywnym do widoku obserwatora. Osie tych obrotów wyrażają wektory:

\begin{samepage}
    \begin{align}
        \label{eq:o_1}
        \vv{h_g} &= \vv{l_{up}} \times \vv {l_{v}}\\
        \vv{v_g} &= \vv{l_{up}}
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\vv{h_g}$} oś obrotu zorientowana poziomo
        \item {$\vv{v_g}$} oś obrotu zorientowana pionowo
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Niech $\vv{d} \in \mathbb{R}^2 $ będzie przesunięciem widoku pochodzącym ze zdarzenia wygenerowanego przez użytkownika, wyrażonym w~pikselach. Współczynnik warunkujący kąt przesunięcia wyrażony jest wzorem:
\begin{samepage}
    \begin{equation}
        \label{eq:o_2}
        s = 0.001 \cdot G_s \cdot \Vert\vv{l_v}\Vert \cdot \Vert\vv{g_v}\Vert
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$G_s$} konfigurowany współczynnik obrotu orbity 
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Kąty obrotu wyrażone w~radianach wyrażone są wzorami:
\begin{samepage}
    \begin{align}
        \label{eq:o_3}
        \theta_x &= s \cdot d_x \\
        \theta_y &= s \cdot d_y
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\theta_x$} kąt obrotu w~osi pionowej, przesuwa widok w~osi $OX$
        \item {$\theta_y$} kąt obrotu w~osi poziomej, przesuwa widok w~osi $OY$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Niech $Q: (\mathbb{R}, \mathbb{R}^3) \to \mathbb{H}$ będzie funkcją konstruującą kwaternion na podstawie kąta i~osi obrotu wyrażoną wektorem jednostkowym. Kwaternion chwilowego obrotu orbity globalnej wyrażony jest wtedy wzorem \ref{eq:o_4}.

\begin{samepage}
    \begin{equation}
        \label{eq:o_4}
        q = Q(\theta_x, \frac{\vv{v}}{\Vert\vv{v}\Vert}) \cdot Q(\theta_y, \frac{\vv{h}}{\Vert\vv{h}\Vert})
    \end{equation}
    \vspace{\baselineskip}
\end{samepage}

Dla każdego zdarzenia przeciągnięcia widoku wygenerowane przez użytkownika dostarczany jest nowy wektor $\vv{d}$. Orbita globalna jest obracana na podstawie obliczonego kwaternionu $q$. Następnie zachodzi potrzeba korekty owego obrotu związana z~trybem kamery i~ustawionymi ograniczeniami jej ruchu. 

\subsection{Obrót orbity lokalnej}
Obrót orbity lokalnej przebiega podobnie co obrót orbity globalnej. Zmianie ulegają wektory, które biorą udział w~wyznaczaniu osi obrotu orbity (równanie \ref{eq:o_5}) oraz współczynniki prędkości obrotu (równanie \ref{eq:o_6}).

\begin{samepage}
    \begin{align}
        \label{eq:o_5}
        \vv{h_l} &= \vv{l_{up}} \times \vv{l_{v}}\\
        \vv{v_l} &= [0, 0, 1]^T
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\vv{h_l}$} oś obrotu zorientowana poziomo
        \item {$\vv{v_l}$} oś obrotu zorientowana pionowo
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

W przypadku orbity lokalnej konieczne było rozdzielenie współczynników $s$ dla kierunku pionowego i~poziomego przesuwania. Obliczane są one według wzorów \ref{eq:o_6} i~\ref{eq:o_7}.

\begin{samepage}
    \begin{align}
        \label{eq:o_6}
        s_x &= -0.008 \cdot L_s \\
        \label{eq:o_7}
        s_y &= 0.004 \cdot L_s
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$L_s$} konfigurowany współczynnik obrotu orbity 
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Przyspieszenia mają inne znaki dlatego, że przeciągnięcie w~osi $OX$ skutkować musi obrotem kamery w~przeciwną stronę. Różne moduły współczynników mają na celu spowolnienie podnoszenia i~opuszczanie kamery względem obracania jej wokół punktu na powierzchni sfery. Z powodu tych zmian kąty obrotu obliczane są następująco:
\begin{samepage}
    \begin{align}
        \label{eq:o_8}
        \theta_x &= s_x \cdot d_x \\
        \theta_y &= s_y \cdot d_y
    \end{align}
    \begin{eqexpl}[25mm]
        \item {$\theta_x$} kąt obrotu w~osi pionowej, przesuwa widok w~osi $OX$
        \item {$\theta_y$} kąt obrotu w~osi poziomej, przesuwa widok w~osi $OY$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}

Tak jak w~przypadku orbity globalnej, końcowy kwaternion obrotu obliczany jest według wzoru \ref{eq:o_4}. Po wykonaniu obrotu o kwaternion $q$, następuje jego korekta związana z~ograniczeniami ruchu kamery zdefiniowanymi dla orbity lokalnej.

\subsection{Ograniczenia ruchu orbit}

\subsubsection{Obliczanie współrzędnych geograficznych na podstawie wektorów orbity.}
Powiązanie współrzędnych geograficznych z~orbitą ma sens tylko w~przypadku orbity globalnej, ponieważ reprezentuje ona obrót części ruchomej wizualizacji. Obie orbity jednak współdzielą ustawienia definiowane za pomocą owych współrzędnych.

Niech $P:\,(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^3$ będzie funkcją rzutującą wektor na płaszczyznę określoną jej wektorem normalnym i~normalizującą go, a~$A: \mathbb{H} \to \mathbb{R}$ funkcją ekstrahującą kąt obrotu z~kwaternionu. Niech $Q:(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{H}$ będzie funkcją konstruującą kwaternion obrotu na podstawie dwóch wektorów jednostkowych. Obliczenie długości i~szerokości geograficznej na podstawie wektorów orbity globalnej wyrażone jest wzorami \ref{eq:o_9} i~\ref{eq:o_10}.

\begin{samepage}
  \begin{align}
    q &= Q\Big(P(\vv{g_v}, \vv{g_{up}}), P([0, 0, 1]^T, \vv{g_{up}})\Big) \\
    \label{eq:o_9}
    long &= A(q) \cdot sgn([q_b, q_c, q_d]^T \cdot [0, 0, 1]^T) \\
    p &= Q\Big(P(\vv{g_{up}}, [0, 0, 1]^T), [0, 0, 1]^T\Big) \\
    \label{eq:o_10}
    lat &= A(p) \cdot sgn([0, 0, 1]^T \cdot \vv{g_{up}})
  \end{align}
\begin{eqexpl}[25mm]
    \item {$long$} długość geograficzna w~przedziale $\langle\ang{-180}; \ang{180}\rbrack$
    \item {$lat$} szerokość geograficzna w~przedziale $\langle\ang{-90}; \ang{90}\rbrack$
\end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Obliczenie długości i~szerokości geograficznej na podstawie wektorów orbity lokalnej wyrażone jest wzorami \ref{eq:o_11} i~\ref{eq:o_12}.

\begin{samepage}
  \begin{align}
    q &= Q\Big(P(\vv{l_v}, [0, 0, 1]^T), P([0, -1, 0]^T, [0, 0, 1]^T)\Big) \\
    \label{eq:o_11}
    long &= A(q) \cdot sgn([q_b, q_c, q_d]^T \cdot [0, 0, 1]^T) \\
    p &= Q\Big(P(\vv{l_{v}}, [0, 0, 1]^T), \vv{l_{v}}\Big) \\
    \label{eq:o_12}
    lat &= A(p) \cdot sgn([0, 0, 1]^T \cdot \vv{l_{v}})
  \end{align}
\begin{eqexpl}[25mm]
    \item {$long$} długość geograficzna w~przedziale $\langle\ang{-180}; \ang{180}\rbrack$
    \item {$lat$} szerokość geograficzna w~przedziale $\langle\ang{-90}; \ang{90}\rbrack$
\end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Ograniczenia pozycji sprowadza się do skonstruowania kwaternionu, który redukuje nadmiarowy obrót do ostatniej dozwolonej pozycji. Potrzebny obrót musi być złożeniem obrotów w~osiach długości i~szerokości geograficznej.
Dla orbity globalnej i~lokalnej osie te wyrażone są wektorami:
\begin{samepage}
  \begin{align}
      \vv{lat_g} &= [0, 0, 1]^T \times \vv{g_{up}} \\
      \vv{long_g} &= \vv{g_{up}} \\
      \vv{lat_l} &= \vv{l_{up}} \times \vv{l_v} \\
      \vv{long_l} &= [0, 0, 1]^T
  \end{align}
  \begin{eqexpl}[25mm]
      \item {$\vv{lat_g}$} oś obrotu orbity globalnej dla szerokości geograficznej
      \item {$\vv{long_g}$} oś obrotu orbity globalnej dla długości geograficznej
      \item {$\vv{lat_l}$} oś obrotu orbity lokalnej dla szerokości geograficznej
      \item {$\vv{long_l}$} oś obrotu orbity lokalnej dla długości geograficznej
  \end{eqexpl}
  \vspace{\baselineskip}
\end{samepage}

Podczas korekty ruchu orbita jest obracana wokół wyliczonych osi o~kąt, który wynika z~różnicy pierwotnych współrzędnych i~współrzędnych ograniczających widok.

\subsection{Tryb kompasu}

Tryb kompasu dla orbity globalnej wymaga wykonania jeszcze jednego obrotu korekcyjnego. W momencie włączenia trybu kompasu zapisany zostaje wektor $\vv{c_n}$ wyliczony ze wzoru \ref{eq:compass_1}, który definiuje obecną orientację kierunku północnego.

Niech $P:\,(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^3$ będzie funkcją rzutującą wektor na płaszczyznę określoną jej wektorem normalnym. Wtedy:

\begin{samepage}
  \begin{equation}
    \label{eq:compass_1}
      \vv{c_n} = P(\vv{g_{up}}, \vv{l_v})
  \end{equation}
  \vspace{\baselineskip}
\end{samepage}



$Q:(\mathbb{R}^3, \mathbb{R}^3) \to \mathbb{H}$ jest funkcją konstruującą kwaternion obrotu na podstawie dwóch wektorów jednostkowych. Konstrukcja kwaternionu korekcji dla trybu kompasu kamery przedstawiona jest na równaniu \ref{eq:compass_2}.
\begin{samepage}
  \begin{equation}
    \label{eq:compass_2}
      q = Q\Big(\normalize{\vv c_n}, \normalize{\vv{lat_g}}\Big)
  \end{equation}
  \vspace{\baselineskip}
\end{samepage}

\subsection{Animacje - płynność ruchów}

Sterowanie kamerą jest przyjemniejsze w~odbiorze i~bardziej intuicyjne, jeśli poszczególne automatyczne operacja zmiany widoku są płynne, a~nie skokowe. Komponent Silnika obsługuje następujące animacje:
\begin{enumerate}
    \item Wytracanie prędkości obrotu orbity globalnej. Kiedy użytkownik zwolni przycisk myszy podczas obracania widoku, ruch nie zatrzymuje się od razu.
    \item Animacja przybliżania i~oddalania kamery.
    \item Orientowanie kamery w~kierunku północnym.
\end{enumerate}

Animacje posiadają konfigurowalny czas trwania i~w celu wyliczenia pozycji pośredniej orbit korzystają z~interpolacji liniowej i~sferycznej\cite{Slerp} wektorów (równanie \ref{eq:q_1}).
\begin{samepage}
    \begin{equation}
      \label{eq:q_1}
        Slerp (q_0, q_1, t) = q_0(q_0^{-1} q_1)^t
    \end{equation}
    \begin{eqexpl}[25mm]
        \item {$q_0$} kwaternion początkowy
        \item {$q_1$} kwaternion końcowy
        \item {$t$} postęp interpolacji w~przedziale $\lbrack0;1\rbrack$
    \end{eqexpl}
    \vspace{\baselineskip}
\end{samepage}
\begin{multicols}{2}
    
    Postęp interpolacji $t$ modyfikowany jest przez konfigurowalną funkcję wygładzającą \mbox{$f: X \to Y$} gdzie \mbox{$X, Y \in \lbrack0;1\rbrack$}. Domyślnie używaną funkcją jest \textit{cubicOut}, której wzór i~wykres przedstawiony jest na rysunku \ref{fig:ease_1}.
    
    \columnbreak

    \begin{figure}[H]
        \centering
        \begin{tikzpicture}[scale=0.7]
            \begin{axis}[domain=0:1,xmin=0,xmax=1.1,ymin=0,ymax=1.1,xlabel=$t$, ylabel=$f(t)$, legend pos=south east]
                \addplot[blue, ultra thick] {1-(1-x)^3)};
                \addlegendentry{$f(t) = 1 - (1-t)^3$};
            \end{axis}
        \end{tikzpicture}
        \caption{Funkcja wygładzająca \textit{cubicOut}}
        \label{fig:ease_1}
    \end{figure}
    
\end{multicols}

\subsection{Macierze transformacji obiektów na podstawie orbit}

Niech $T : \mathbb{R}^3 \to \mathbb{R}^{4\times4}$ będzie funkcją konstruującą macierz translacji na podstawie wektora w~przestrzeni trójwymiarowej. Niech $R : (\mathbb{R}^3, \mathbb{R}^3, \mathbb{R}^3) \to \mathbb{R}^{4\times4}$ będzie funkcją konstruującą macierz obrotu obserwatora, aby patrzył na dany punkt w~odpowiedniej orientacji. Macierz transformacji grupy obrotu, czyli ruchomej części wizualizacji, wyrażona jest równaniem \ref{eq:t_1}. Macierz transformacji obiektu kamery wyrażona jest równaniem \ref{eq:t_2}.

\begin{align}
    \label{eq:t_1}
      M_g &= T([0, 0, -\Vert\vv{g_v}\Vert]^T) \cdot R([0, 0, 0]^T, -\vv{g_v}, \vv{g_{up}}) \\
    \label{eq:t_2}
      M_l &= T(\vv{l_v}) \cdot R(\vv{l_v}, [0, 0, 0]^T, \vv{l_{up}})
\end{align}

\section{Implementacja}

Komponent Silnika zaimplementowany został w~języku TypeScript\cite{TypeScript}. Jest on nadzbiorem języka JavaScript i~umożliwia korzystanie ze statycznego typowania, które w~JavaScripcie nie jest możliwe. Udostępnia tworzenie unii typów, zawiera mechanizmy ich inferencji. Wprowadza wzorzec dekoratorów, zawiera obsługę formatu JSX i~dodaje zmienne wyliczeniowe. Rozszerza możliwości programowania obiektowego o~typy generyczne. Przed uruchomieniem musi być transpilowany do języka JavaScript. Walidacja utworzonego kodu pod względem poprawności typowania następuje w~momencie transpilacji i~nie jest dokonywana podczas jego wykonywania. 

Zaletą stosowania statycznego typowania jest zniwelowanie możliwości pomyłek programisty związanych z~nieznajomością interfejsów używanych klas i~modułów. Statycznie typowany kod sam w~sobie stanowi źródło swojej dokumentacji, a~mechanizmy refleksji pozwalają na jeszcze bardziej rozległą walidację typów i~dynamiczne generowanie dokumentacji.

Systemu wizualizacji danych geograficznych jako całość nazwany został \textit{GeoVis}, co jest skrótem wyrażenia \textit{\textbf{Geo}graphic \textbf{Vis}ualization}. Komponent Silnika przyjął nazwę \mbox{\textit{GeoVisEngine}} i~składa się z~modułu \mbox{\textit{GeoVisCore}}, który osadzony jest w~eksportowanym komponencie \mbox{\textit{GeoVisCoreVue}}. Relację pomiędzy ogólnymi komponentami przedstawiona jest na diagramie~\ref{fig:c3_geo_vis_engine}. Kod silnika podzielony został na domeny, które realizują zadania według odkreślonej odpowiedzialności. Są to:

\begin{enumerate}
    \item \texttt{Animation} - obsługuje animacje, udostępnia mechanizmy definiowania transformacji pomiędzy dwoma obiektami z~użyciem wybranej funkcji wygładzającej i~zdefiniowanym czasem.
    \item \texttt{Camera} - zarządza ruchami kamery, udostępnia interfejs \texttt{TrackballCamera} dostępny od strony wizualizacji.
    \item \texttt{GeoPosition} - zawiera definicję obiektów orbit i~współrzędnych geograficznych. Odpowiedzialna jest również za transformacje pomiędzy współrzędnymi geograficznymi, a~trójwymiarową sceną.
    \item \texttt{Utils} - zawiera funkcje pomocnicze.
    \item \texttt{Visualization} - zawiera klasy bazowe definiujące wizualizację oraz ich przykłady.
\end{enumerate}

\begin{figure}
    \centering 
    \includegraphics[scale=0.6]{diagrams/out/c3_geo_vis_engine.png}
    \caption{Zależności głównych komponentów Silnika}
    \label{fig:c3_geo_vis_engine}
\end{figure}

\subsection{GeoVisCore}

\textit{GeoVisCore} jest komponentem odpowiedzialnym za dostarczenie elementu \texttt{Canvas}, który następnie osadzony jest w~komponencie \textit{GeoVisCoreVue} opisanym w~dalszej części pracy. \textit{GeoVisCore} obsługuje zdarzenia wygenerowane przez użytkownika pochodzące z~elementu \texttt{Canvas}. Zdarzeniami tymi są te, związane z~myszką i~klawiaturą. Komponent realizuje cykl życia wizualizacji, wyświetlając opisane przez nią obiekty i~propagując zdarzenia pochodzące od użytkownika. To w~tym komponencie osadzone jest środowisko biblioteki Three.js.
W opisie implementacji najpierw zostanie przedstawiona struktura i~zależności każdej z~klas i~komponentów, a~następnie opisany zostanie cykl życia wizualizacji.

Klasa \texttt{GeoVisCore}, której despośrednie zależności przedstawia diagram \ref{fig:c3_geo_vis_core}, jest głównym elementem komponentu Silnika. Inicjalizuje one zależności ekosystemu biblioteki Three.js, odpowiada za obsługę elementu \texttt{Canvas} oraz za uruchamianie i~aktualizowanie wizualizacji. Sterowanie wyświetlaną wizualizacją odbywa się za pomocą metody \mbox{\texttt{GeoVisCore.run(v: Visualization)}}. Przy kolejnych jej wywołaniach instancje obiektów starej wizualizacji są usuwane. Ma to miejsce również podczas wywołania metody \mbox{\texttt{GeoVisCore.destroy()}}, która powoduje wyjście z~głównej pętli animacji i~zamknięcie instancji komponentu.

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_geo_vis_core.png}
    \caption{Diagram klas dla klasy \texttt{GeoVisCore}}
    \label{fig:c3_geo_vis_core}
\end{figure}

Najważniejszą klasą, odpowiedzialną za sterowanie kamerą, jest klasa \texttt{TrackballController}. Implementuje ona interfejs \texttt{TrackballCamera}, który definiuje metody sterowania kamerą dostępne dla twórcy wizualizacji. Diagram najważniejszych zależności klasy \texttt{TrackballController} pokazano na rysunku \ref{fig:c3_trackball}. W celu zachowania czytelności, na diagramie nie uwzględniono metod i~atrybutów klas in interfejsów.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{diagrams/out/c3_trackball.png}
    \caption{Diagram klas dla klasy \texttt{TrackballController} i~najważniejszych zależności}
    \label{fig:c3_trackball}
\end{figure}

Ze względów bezpieczeństwa kod wykonujący się w~przeglądarce nie ma dostępu do niczego, poza obsługiwaną stroną. Wykonuje się on również tylko na jednym wątku, aby uniknąć typowych problemów programów wielowątkowych takich jak wyścigi czy trudniejsze zarządzenie i~współdzielenie pamięci. W typowych przypadkach aplikacje webowe przez większość czasu są bezczynne i~większość kodu, który wykonuje się na stronie, wyzwalany jest za pomocą zdarzeń wysyłanych przez przeglądarkę. Dlatego JavaScript opiera swoje działania na tak zwanym EventLoop. Jest to pętla, która, w~dużym uproszczeniu, obsługuje zdarzenia z~określonym priorytetem, kładąc nacisk na responsywność interfejsu użytkownika. Przykładem takich zdarzeń może być naciśnięcie przycisku myszy, ale też żądanie wygenerowanie klatki animacji. Wszystko sprowadza się do asynchronicznego wykonania zdefiniowanej procedury obsługi takiego zdarzenia. JavaScript definiuje zaimplementowany w~obiektach DOM interfejs EventTarget\cite{JsEvents}, który umożliwia zdefiniowanie funkcji wykonywanej po zajściu zdarzenia. Zdarzenia identyfikowane są jako ciąg znaków. Wykorzystując przewagę języka TypeScript możemy tworzyć, emitować i~obsługiwać zdarzenia, gdzie każdy aspekt będzie posiadał statyczne typowanie, włączając w~to samą abstrakcję zdarzenia i~dane jakie są z~nim powiązane. W tym celu wykorzystano bibliotekę o~nazwie \texttt{strongly-typed-events}\cite{Events} implementującą to podejście. Interface \texttt{TrackballCamera} korzysta z~interfejsu \texttt{IEvent} dostarczonego przez tę bibliotekę (diagram \ref{fig:c3_trackball}). Różnica pomiędzy obsługą zdarzeń w~JavaScripcie i~z możliwościami TypeScriptu przedstawiają listingi \ref{lst:events_1} i~\ref{lst:events_2}.

\begin{lstlisting}[language=javascript, label={lst:events_1}, caption={Obsługa zdarzenia w~języku JavaScript}]
const event = new Event('event');
event['payload'] = "testData";
elem.addEventListener('event', (data) => {
    console.log(data.payload) 
}, false);

elem.dispatchEvent(event); // prints: testData
\end{lstlisting}

\begin{lstlisting}[language=javascript, label={lst:events_2}, caption={Obsługa zdarzenia w~języku TypeScript z~wykorzystaniem biblioteki \texttt{strongly-typed-events}}]
const onEvent = new SimpleEventDispatcher<{payload: string}>();
onEvent.asEvent().sub((data) => {
    console.log(data.payload); 
})

onEvent.dispatch({payload: 'testData'});  // prints: testData
\end{lstlisting}

\texttt{TrackballController} realizuje operacje obrotów orbit opisane w~rozdziale \ref{sec:camera}. Orbity reprezentowane są przez obiekty \texttt{GlobalOrbit} i~\texttt{LocalOrbit} dziedziczące po klasie \texttt{Orbit}, które realizuje wspólne operacja dla obu z~nich. Są to między innymi wykonywanie obrotów korekcyjnych dla pozycji kamery i~orientacji w~kierunku północnym. Wspólną funkcjonalność różni układ odniesienia obu orbit i~dlatego wydzielono metody abstrakcyjne klasy \texttt{Orbit}. Jej klasy pochodne implementują je inaczej, zwracając różne wektory. Klasa \texttt{AnimatedTransition} reprezentuje animację pojedynczego obiektu. Zawiera ona swój własny zegar i~pozwala zdefiniować długość oraz funkcję wygładzającą.

Ukrycie faktycznej implementacji kontrolera kamery za interfejsem \texttt{TrackballCamera} daje późniejszą możliwość zastąpienia jej inną. Realizując ten sam interfejs, nie będzie ona wpływać na już utworzone wizualizacje i~pozostałą część aplikacji. 

\section{Wizualizacja}

Kwestia definiowana wizualizacji wyświetlanych przez złożony system, poruszona we wstępie, jest ważna z~punktu widzenia twórcy wizualizacji. Projektowany system proponuje definicję wizualizacji jako obiektu implementującego dostarczony interfejs. Abstrakcyjna klasa \texttt{Visualization} definiuje metody niezbędne do osadzenia obiektów sceny, definicję metadanych, aktualizacji wizualizacji i~jej usuwania. Jest to najważniejsza klasa przy definiowaniu wizualizacji, więc każda jej część wymaga dokładnego opisu. Klasa i~jej najważniejsze zależności zostały przedstawione na diagramie \ref{fig:c3_vis}.

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_vis.png}
    \caption{Diagram klas dla klasy \texttt{Visualization} i~najważniejszych zależności}
    \label{fig:c3_vis}
\end{figure}

Wizualizacje, mogą zawierać osadzone inne wizualizacje tworząc strukturę drzewiastą zależnych wizualizacji. Przykładem może być prosta wizualizacja przestrzeni kosmicznej, która może być rodzicem dla wizualizacji Ziemi, ale też innych planet.
\begin{samepage}
    Pola klasy \texttt{Visualization} dzielą się na abstrakcyjne i~te definiowane przez klasę basową, wywoływane wewnętrznie:

    %TODO: Pytanko: Przerobić to na tabelę?

    \begin{itemize}
        \item \texttt{parents} - tablica mieszcząca obiekty wizualizacji - rodziców,
        \item \texttt{meta} - obiekt typu \texttt{VisualizationMeta} przechowujący informacje o~wizualizacji widoczne w~panelu kontrolnym aplikacji, i~dostępnym z~poziomu interfejsu użytkownika,
        \item \texttt{name} - identyfikator wizualizacji, używany do jednoznacznej identyfikacji obiektu wizualizacji,
        \item \texttt{setupOwnMeta} - metoda umożliwiająca wizualizacji ustawienie swoich metadanych,
        \item \texttt{setupScene} - metoda umożliwiająca wizualizacji osadzenie na scenie i~w grupie obiektów~3D,
        \item \texttt{setupCamera} - metoda umożliwiająca wizualizacji modyfikację domyślnym ustawień kamery,
        \item \texttt{update} - metoda wywoływana co każdą klatkę animacji, służy do aktualizacji obiektów wizualizacji,
        \item \texttt{destroy} - metoda wykorzystywana do usuwania obiektów i~czyszczenia pamięci,
        \item \texttt{addParent} - metoda umożliwiająca dodanie wizualizacji - rodzica, wywoływana typowo w~konstruktorze,
        \item \texttt{getControls} - metoda umożliwiająca wizualizacji zdefiniowanie swojego panelu kontrolnego w~postaci komponenty frameworka Vue,
        \item \texttt{\_setupMeta} - metoda wywoływana wewnętrznie dla całego drzewa wizualizacji obsługująca ustawianie metadanych,
        \item \texttt{\_setup} - metoda wywoływana wewnętrznie dla całego drzewa wizualizacji, odpowiedzialna za wywołanie metod \texttt{setupCamera} i~\texttt{setupScene},
        \item \texttt{\_update} - metoda odpowiedzialna za aktualizowanie całego drzewa wizualizacji,
        \item \texttt{\_destroy} metoda odpowiedzialna za niszczenie całego drzewa wizualizacji.
    \end{itemize}
\end{samepage}

\begin{samepage}
Metadane wizualizacji przechowywane są w~obiekcie typu \texttt{VisualizationMeta} implementującego interfejs \texttt{IVisualizationMeta}, który to dostępny jest od strony aplikacji. Interfejs metadanych definiuje następujące pola:

\begin{itemize}
    \item \texttt{title} - tytuł wizualizacji,
    \item \texttt{description} - opis wizualizacji,
    \item \texttt{author} - autor wizualizacji,
    \item \texttt{keywords} - słowa kluczowe zapisane w~tablicy,
    \item \texttt{thumbnailB64} - miniaturka wizualizacji zapisana jako ciąg znaków kodujący obraz kodowaniem Base64~\cite{Base64}.
\end{itemize}

Wszystkie pola, poza polem \texttt{keywords}, są nadpisywane przez dziedziczące wizualizacje. Tablica \texttt{keywords} za każdym wywołaniem metody \texttt{addKeywords} jest rozszerzana o~nowe słowa kluczowe, a~ich ewentualne duplikaty są usuwane.
 
\end{samepage} 

\begin{samepage}
    \begin{lstlisting}[float, language=javascript, label={lst:vis}, caption={Pusta  klasa wizualizacji \texttt{EmptyVis} rozszerzająca klasę \texttt{Visualization}}]
import { VueConstructor } from "vue/types/umd";
import * as THREE from "three";
import TrackballCamera from "../../../../../core/domain/Camera/interfaces/TrackballCamera";
import Visualization from "../../../../../core/domain/Visualization/models/Visualization";
import VisualizationMeta from "../../../../../core/domain/Visualization/models/VisualizationMeta";

/**
 * Example of empty visualization
 * @category VisualizationExamples
 */
export default class EmptyVis extends Visualization {
  constructor() {
    super("emptyVis");
    Object.seal(this);
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  public setupCamera(camera: TrackballCamera): void {
    //
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  public setupScene(scene: THREE.Scene, group: THREE.Group): void {
    //
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  public update(deltaFactor: number): void {
    //
  }

  public destroy(): void {
    //
  }

  public getControls(): Vue | VueConstructor<Vue> | null {
    return null;
  }

  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  public setupOwnMeta(meta: VisualizationMeta): void {
    //
  }
}
    \end{lstlisting}
\end{samepage}

Opisane wcześniej klasy i~interfejsy obsługują cykl życia wizualizacji. Składają się na niego utworzenie obiektu wizualizacji i~umieszczenie jej w~komponencie \texttt{GeoVisCore}. Komponent ten dalej zajmuje się inicjalizacją wszystkich obiektów sceny definiowanych przez wizualizację oraz modyfikacją ustawień kamery. Podczas każdej iteracji pętli głównej animacji aktualizowane są położenie kamery oraz sama wizualizacja. Biblioteką obsługiwaną w~głównej pętli animacji, ułatwiającą tworzenie animacji, jest Tween.jyrażone jest równaniems~\cite{TWEEN}. Po zmianie wizualizacji na inną lub po wyłączeniu komponentu, stara wizualizacja jest niszczona. Uogólniony diagram cyklu życia animacje przedstawiono na rysunku~\ref{fig:c3_lifecycle}. Szczegółowy diagram sekwencji przedstawiono na rysunku~\ref{fig:c3_lifecycle_seq}. 

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_lifecycle.png}
    \caption{Diagram aktywności cyklu życia wizualizacji}
    \label{fig:c3_lifecycle}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{diagrams/out/c3_lifecycle_seq.png}
    \caption{Diagram sekwencji cyklu życia wizualizacji}
    \label{fig:c3_lifecycle_seq}
\end{figure}

\subsection{Vue.js i~Webpack}

Dotychczas opisane elementy służyły tylko i~wyłącznie do obsługi grafiki wyświetlanej za pomocą elementu \texttt{Canvas}. Oprócz tego Silnik nakłada na niego komponenty odpowiedzialne za obsługę sterowania kamery oraz wyświetlające informacje o~jej położeniu. Wyświetlają one również metadane wizualizacji oraz obsługują dostarczony przez nią komponent sterujący. 

Vue.js jest frameworkiem języka JavaScript skupiający się w~dużej mierze na wyświetlaniu i~aktualizowaniu zdefiniowanych widoków~\cite{Vue}. Określany jest przez twórców jako \textit{priogresywny}, ponieważ posiada wysokie zdolności to adaptacji i~integracji z~innymi bibliotekami oraz tworzony jest z myślą o niskim progu wejścia. Inne funkcjonalności, takie jak obsługa routera, czy przechowywanie globalnego stanu aplikacji, oferują oficjalne biblioteki poboczne. W tworzeniu interfejsu użytkownika, tak jak inne popularne biblioteki, proponuje podejście oparte na komponentach. Gdzie rozwój i~testowanie skupia się na zawartych w~pojedynczych plikach, w~pełni funkcjonalnych części interfejsu. Podejście to pozwala na izolację testowanych komponentów, łatwe zarządzenie nimi oraz ich ponowne użycie w~innych aplikacjach. Vue.js nie oferuje jednoznacznie zdefiniowanego monolitycznego środowiska uruchomieniowego. Nie stoi to na przeszkodzie, aby takie zdefiniowane środowisko powstało. Przykładem jest takiego środowiska jest framework Nuxt.js oparty na Vue.js~\cite{Nuxt}. Vue.js w~wersji drugiej nie był pisany tak, aby w~pełni wspierać język TypeScript, choć mimo to typy dostarczonych obiektów są eksportowane razem z~nimi. Brak kompatybilności jest widoczny między innymi w~przypadku eksportu typów podczas budowania biblioteki komponentu oraz w~samej konfiguracji projektu i~oficjalnych bibliotek pobocznych. Wersja trzecia frameworka została kompletnie oparta na języku TypeScript. 

Komponent Silnika eksportowany jest jako komponent Vue.js, który posiada osadzony element \texttt{Canvas} razem z~modułem \texttt{GeoVisCore}. Eksportowane są również przykładowe wizualizacje i~wszystkie potrzebne użytkownikowi Silnika klasy i~interfejsy. Komponent ten może być później zaimportowany i~osadzony w~dowolnym innym komponencie aplikacji chcącym wyświetlać wizualizacje. Konstrukcja struktury projektu w~taki sposób daje wszystkie korzyści, jakie daje rozwój aplikacji opartej na komponentach. Są to między innymi opisane wcześniej izolowane testowanie i~możliwość wielokrotnego użycia komponentów. 

Vue do definicji komponentów proponuje format plików zwany SFC (ang. Single File Component). Jeden taki plik w~pełni definiuje zachowanie i~wygląd komponentu. Zawiera on trzy sekcje: \texttt{template}, przechowującą kod HTML komponentu opatrzony nieraz specjalnymi dyrektywami frameworka, \texttt{script}, przechowującą właściwą definicję obiektu komponentu i~model jego danych, oraz \texttt{style}, gdzie umieszczany jest kod kaskadowych arkuszy stylów, których zakres może być globalny lub ograniczony tylko do właściwego sobie komponentu. Pliki w~takiej formie nie są rozumiane przez przeglądarkę i~przed uruchomieniem muszą być odpowiednio przetworzone. Sposobem na przetworzenie tych plików jest użycie tzw. \textit{module bundlera}, który potrafi zebrać wiele plików w~różnych formatach do zasobów rozumianych przez przeglądarkę - Kodu HTML, JavaScript i~CSS. W ekosystemie Vue.js tego typu rozwiązanie oferuje \mbox{Webpack~\cite{Webpack}.} Opiera się on na koncepcji \textit{loaderów}, skryptów, które z~użyciem właściwych sobie bibliotek tworzą łańcuch kolejnych transformacji dla plików konkretnych formatów. Dzięki temu aplikacja może być zbudowana z~wielu plików źródłowych, które mogą pisane być w~różnych formatach i~mieć różne odpowiedzialności, a~i~tak finalnie złożonych do jednego skryptu wynikowego. Alternatywami Webpacka są między innymi Parcel~\cite{Parcel}~i Rollup~\cite{Rollup}.

Przykładem plików przetwarzanych przez Webpacka są pliki \texttt{*.vue}, gdzie uproszczony łańcuch transformacji, właściwy dla konfiguracji komponentu Silnika, przedstawiony jest na rysunku~\ref{fig:c3_webpack}. Loader \texttt{vue-loader} rozdziela pliki \texttt{*.vue} na trzy wcześniej opisane części i~każdą z~nich traktuje jako odzielny moduł wymagający własnego przetworzenia. Loader \texttt{ts-loader} dokonuje transpilacji kodu z~języka TypeScript na JavsScript, a~\texttt{sass-loader} transpiluje style z~notacji SCSS i~SASS na CSS.

\begin{figure}
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_webpack.png}
    \caption{Uproszczony łańcuch transformacji plików \texttt{*.vue}}
    \label{fig:c3_webpack}
\end{figure}

\subsubsection{Komponenty Vue.js interfejsu użytkownika}

Struktura komponentów przedstawiona została na rysunku~\ref{fig:c3_vue}. Komponent \texttt{GeoVisCoreVue} jest komponentem eksportowanym i~przeznaczonym do osadzenia w~aplikacji używającej komponentu Silnika. Zarządza on elementem \texttt{Canvas} oraz instancją klasy \texttt{GeoVisCore} i~zagnieżdża pozostałe komponenty interfejsu użytkownika. Eksportowany jest on jako transpilowany kod w~języku TypeScript zawierający poprawne adresy do również skopiowanych plików zasobów, takich jak tekstury i~ikony. Równolegle eksportowane są typy w~plikach \texttt{*.d.ts}, które umożliwiają korzystanie ze statycznego typowania przy wykorzystaniu komponentu Silnika.

Komponenty tworzą strukturę drzewiastą. Przekazywanie danych pomiędzy nimi może zachodzić w~dwie strony. Od góry do dołu dane, zmienne i~stałe, mogą być przekazywane poprzez tzw. \textit{properties}, definiowane w~szablonie tak jak atrybuty znacznika HTML. W górę drzewa dane przekazywane są za pomocą zdarzeń, które to komponent musi wyemitować, a~komponent go zagnieżdżający może je obsłużyć. Komponent \texttt{GeoVisCoreVue} do poprawnego działania potrzebuje obiektu wyświetlanej wizualizacji, który jest przekazywany przez \textit{property} \texttt{visualization}.

Do podstawowych komponentów, takich jak przyciski, czy też komponenty siatki, użyty został framework Vuetify~\cite{Vuetify}. Dostarcza on wysoce konfigurowalne komponenty w~stylu \texttt{Material Design}. Nazwy konponentów tego frameworka oznaczone przedrostkiem \texttt{v}, na przykład \texttt{v-btn}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.6]{diagrams/out/c3_vue.png}
    \caption{Struktura komponentów Vue.js Silnika}
    \label{fig:c3_vue}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/c3_controls.png}
    \caption{Elementy kontrolne wizualizacji}
    \label{fig:c3_controls}
\end{figure}


Komponent \texttt{CoreControls}, nałożony na element \texttt{Canvas}, pokazany na rysunku \ref{fig:c3_controls}, odpowiedzialny jest głównie za pracę prawego panelu kontrolnego. Zagnieżdża on komponent \texttt{Compass}, po którego kliknięciu wywoływana jest metoda \texttt{rotateNorth} kontrolera kamery. Przyciski poniżej odpowiedzialne są za przybliżanie i~oddalanie kamery - metody \texttt{zoomIn} i~\texttt{zoomOut} kontrolera kamery. Kompas oraz współrzędne geograficzne widoczne na lewo od skrajnego prawego panelu aktualizowane są na skutek wyemitowania zdarzenia \texttt{onNorthAngleChange} i~\texttt{onGlobalOrbitChange} przez kontroler kamery. Aktualizacja wyświetlanych danych z~każdą emisją odpowiadającym im zdarzeń nie jest potrzebna i~powodowałaby straty wydajności. Wykorzystywany jest tutaj mechanizm \texttt{throttle}, który dostarcza biblioteka Lodash~\cite{lodash}. Zdarzenia obsługiwane są minimalnie co $142,85$~ms. 
\texttt{CoreControls} zagnieżdża też panel wyświetlający metadane oraz panel kontrolny dostarczany przez wizualizację. Po lewej stronie ekranu znajduje się przycisk pokazujący i~ukrywający dodatkowy panel (rysunki~\ref{fig:c3_controls} i~\ref{fig:c3_controls_open}). Po kliknięciu na zakładkę \textit{Controls}, ukazuje się panel kontrolny wizualizacji (rysunek~\ref{fig:c3_controls_earth}).


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{img/c3_controls_open.png}
    \caption{Elementy kontrolne wizualizacji - otwarty panel dodatkowy}
    \label{fig:c3_controls_open}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[scale=2.1]{img/c3_controls_earth.png}
    \caption{Elementy kontrolne wizualizacji - panel kontrolny wizualizacji}
    \label{fig:c3_controls_earth} 
\end{figure}

\section{Podsumowanie}

Komponent Silnika jest najważniejszym komponentem aplikacji. To on odpowiada za wyświetlanie i~kontrolę nad wizualizacją. Rozdział ten opisywał technologie użyte do definiowania oraz wyświetlania sceny. W pełni też opisał zasady pracy kamery, która może orbitować wokół środka grupy obrotu, oraz niezależnie nad punktem na powierzchni sfery. Wykorzystuje w~tym celu abstrakcję orbity globalnej i~lokalnej. Orbity mogą mieć zdefiniowane ograniczenia obrotu, a~kamera może utrzymywać stałą orientację w~kierunku północnym w~trybie kompasu. Opisano również mechanizmy odpowiedzialne za animację transformacji widoku kamery.

Następnie przedstawiona została implementacja systemu z~wykorzystaniem języka TypeScript, biblioteki Three.js i~frameworka Vue.js. Dokładnie opisany został również sposób definiowania wizualizacji w~postaci klasy dziedziczącej po klasie \texttt{Visualization}. Opisano też sposób budowania eksportowanej wersji komponentu Silnika z~użyciem narzędzia Webpack.

Jak się później okazało, użycie bazowej konfiguracji Webpacka proponowanej przez Vue.js nie wspiera eksportowania typów języka TypeScript, co uniemożliwia korzystanie ze statycznego typowania w~momencie zaimportowania komponentu w~innej aplikacji. Konicznym było eksportowanie ich poza głównym procesem budowania komponentu. Było to możliwe jedynie dla plików \texttt{*.ts}. Pliki \texttt{*.vue} zostały w~tym procesie pominięte, ponieważ nie mogą być przetworzone natywnie przez narzędzie \texttt{tsc}. Nie stanowi to dużego problemu, ponieważ najważniejszym elementem wymagającym statycznego typowania jest interfejs \texttt{TrackballCamera} oraz klasy przykładowych wizualizacji.

Użycie plików zasobów eksportowanych wraz z~komponentem Silnika w~docelowej aplikacji, takich jak tekstury, czy też ładowane asynchronicznie skrypty, wymaga ręcznego ich skopiowania w~odpowiednie miejsce, aby były dostępne możliwe do pobrania z~użyciem serwera plików statycznych. Jest to spowodowane tym, że Webpack, ładując pliki, kopiuje je do zdefinowanej lokalizacji. Dla tych plików, w~transpilowanym kodzie, ustawia on odpowiedni adres, który nie zmieni się po zaimportowaniu komponentu do innej aplikacji. Obsługa plików statycznych leży w~gestii użytkownika komponentu.

Wiele z~tych problemów spowodowane jest użyciem domyślnej, z~pewnymi modyfikacjami, konfiguracji narzędzie Webpack dla Vue.js. Brak możliwości swobodnej konfiguracji utrudnia rozwiązywanie problemów, które mogą wyniknąć przy budowaniu biblioteki wykorzystującej język TypeScript i~pliki statyczne. Z kolei całkowicie ręczna konfiguracja tego narzędzia jest trudna i~czasochłonna. Przed przystąpieniem implementacji, warto zatem przetestować procedurę budowania na minimalnym i~kompletnym przykładzie.
